{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß† WavLM Weighted Layer Sum Training\n",
                "\n",
                "Questo notebook addestra WavLM con **Weighted Layer Sum**, un'architettura SOTA che combina tutti i 12 hidden states del Transformer con pesi apprendibili.\n",
                "\n",
                "**Vantaggi:**\n",
                "- Layer bassi: informazioni acustiche (formanti, pitch)\n",
                "- Layer alti: informazioni fonetiche/semantiche\n",
                "- Pesi apprendibili: il modello impara la combinazione ottimale"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Ambiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.1 Verifica GPU\n",
                "!nvidia-smi\n",
                "\n",
                "import torch\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA disponibile: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.2 Monta Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "print(\"‚úÖ Drive montato\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.3 Estrai progetto da zip\n",
                "import os\n",
                "import zipfile\n",
                "from pathlib import Path\n",
                "\n",
                "ZIP_PATH = '/content/drive/MyDrive/phonemeRef.zip'\n",
                "EXTRACT_PATH = '/content/DeepLearning-Phoneme'\n",
                "\n",
                "if not os.path.exists(ZIP_PATH):\n",
                "    raise FileNotFoundError(f\"‚ùå File non trovato: {ZIP_PATH}\\nCarica phonemeRef.zip su Google Drive\")\n",
                "\n",
                "print(f\"üì¶ Estrazione {ZIP_PATH}...\")\n",
                "with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
                "    zip_ref.extractall('/content/')\n",
                "\n",
                "# Trova cartella estratta\n",
                "extracted = [f for f in os.listdir('/content/') if os.path.isdir(f'/content/{f}') and 'Phoneme' in f]\n",
                "if extracted:\n",
                "    EXTRACT_PATH = f'/content/{extracted[0]}'\n",
                "\n",
                "os.chdir(EXTRACT_PATH)\n",
                "print(f\"‚úÖ Progetto in: {EXTRACT_PATH}\")\n",
                "!ls -la"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.4 Installa dipendenze\n",
                "!pip install -q transformers datasets evaluate jiwer accelerate soundfile librosa pyyaml tqdm\n",
                "print(\"\\n‚úÖ Dipendenze installate\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preparazione Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.1 Carica dataset\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "\n",
                "# Opzioni dataset\n",
                "DATASET_OPTIONS = [\n",
                "    'data/processed/combined_augmented.csv',\n",
                "    'data/processed/combined_dataset.csv',\n",
                "    'data/processed/phonemeref_processed.csv',\n",
                "]\n",
                "\n",
                "DATASET_CSV = None\n",
                "for opt in DATASET_OPTIONS:\n",
                "    if Path(opt).exists():\n",
                "        DATASET_CSV = opt\n",
                "        break\n",
                "\n",
                "if not DATASET_CSV:\n",
                "    raise FileNotFoundError(\"‚ùå Nessun dataset trovato!\")\n",
                "\n",
                "df = pd.read_csv(DATASET_CSV)\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"   Samples: {len(df):,}\")\n",
                "\n",
                "if 'source' in df.columns:\n",
                "    print(f\"\\nüìä Distribuzione:\")\n",
                "    print(df['source'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.2 Verifica vocab.json\n",
                "import json\n",
                "\n",
                "vocab_path = Path('data/processed/vocab.json')\n",
                "if vocab_path.exists():\n",
                "    with open(vocab_path, encoding='utf-8') as f:\n",
                "        vocab = json.load(f)\n",
                "    print(f\"üìä Vocab: {len(vocab)} simboli\")\n",
                "    print(f\"   Esempio: {list(vocab.keys())[:10]}\")\n",
                "else:\n",
                "    raise FileNotFoundError(\"‚ùå vocab.json non trovato!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configurazione Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.1 Configurazione (ottimizzata per Tesla T4)\n",
                "import yaml\n",
                "import os\n",
                "\n",
                "# === CONFIGURAZIONE PRINCIPALE ===\n",
                "DRIVE_OUTPUT_DIR = '/content/drive/MyDrive/phoneme_wavlm_weighted'\n",
                "\n",
                "config = {\n",
                "    'seed': 42,\n",
                "    'model': {\n",
                "        'name': 'microsoft/wavlm-large',\n",
                "        'freeze_feature_encoder': True\n",
                "    },\n",
                "    'data': {\n",
                "        'csv_path': DATASET_CSV,\n",
                "        'vocab_path': 'data/processed/vocab.json',\n",
                "        'audio_base_path': '.',\n",
                "        'val_size': 0.05,\n",
                "        'test_size': 0.05,\n",
                "        'sampling_rate': 16000\n",
                "    },\n",
                "    'training': {\n",
                "        'output_dir': DRIVE_OUTPUT_DIR,\n",
                "        'num_train_epochs': 10,\n",
                "        'per_device_train_batch_size': 8,\n",
                "        'per_device_eval_batch_size': 8,\n",
                "        'gradient_accumulation_steps': 2,\n",
                "        'dataloader_num_workers': 0,\n",
                "        'dataloader_pin_memory': False,\n",
                "        'learning_rate': 3e-5,\n",
                "        'warmup_steps': 500,\n",
                "        'weight_decay': 0.01,\n",
                "        'optim': 'adamw_torch',\n",
                "        'max_grad_norm': 1.0,\n",
                "        'fp16': True,\n",
                "        'bf16': False,\n",
                "        'eval_strategy': 'epoch',\n",
                "        'save_strategy': 'epoch',\n",
                "        'save_total_limit': 3,\n",
                "        'load_best_model_at_end': True,\n",
                "        'metric_for_best_model': 'per',\n",
                "        'greater_is_better': False,\n",
                "        'logging_steps': 100,\n",
                "        'disable_tqdm': False,\n",
                "        'group_by_length': True,\n",
                "    }\n",
                "}\n",
                "\n",
                "os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "# Salva config\n",
                "with open('configs/training_config_weighted.yaml', 'w') as f:\n",
                "    yaml.dump(config, f, default_flow_style=False)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üìã CONFIGURAZIONE WAVLM WEIGHTED (LARGE)\")\n",
                "print(\"=\"*60)\n",
                "print(f\"üìÅ Output: {DRIVE_OUTPUT_DIR}\")\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"üî¢ Epochs: {config['training']['num_train_epochs']}\")\n",
                "print(f\"üì¶ Batch: {config['training']['per_device_train_batch_size']} x {config['training']['gradient_accumulation_steps']}\")\n",
                "print(f\"üìà LR: {config['training']['learning_rate']}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.2 Verifica checkpoint esistenti\n",
                "from pathlib import Path\n",
                "import json\n",
                "\n",
                "output_dir = Path(DRIVE_OUTPUT_DIR)\n",
                "checkpoints = []\n",
                "\n",
                "if output_dir.exists():\n",
                "    checkpoints = sorted([\n",
                "        d for d in output_dir.iterdir() \n",
                "        if d.is_dir() and d.name.startswith(\"checkpoint-\")\n",
                "    ])\n",
                "\n",
                "print(f\"üìÅ Output: {output_dir}\")\n",
                "if checkpoints:\n",
                "    print(f\"‚úÖ {len(checkpoints)} checkpoint trovati\")\n",
                "    for cp in checkpoints[-3:]:\n",
                "        print(f\"   üìÅ {cp.name}\")\n",
                "else:\n",
                "    print(\"‚ùå Nessun checkpoint - Training partir√† da zero\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.1 Avvia Training con script train_weighted.py\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
                "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
                "\n",
                "# === OPZIONI ===\n",
                "RESUME = \"auto\"\n",
                "\n",
                "drive_path = Path(DRIVE_OUTPUT_DIR)\n",
                "existing_checkpoints = []\n",
                "if drive_path.exists():\n",
                "    existing_checkpoints = sorted([\n",
                "        d for d in drive_path.iterdir() \n",
                "        if d.is_dir() and d.name.startswith(\"checkpoint-\")\n",
                "    ])\n",
                "\n",
                "if RESUME == \"auto\":\n",
                "    do_resume = len(existing_checkpoints) > 0\n",
                "else:\n",
                "    do_resume = bool(RESUME)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üöÄ AVVIO TRAINING WAVLM WEIGHTED (LARGE)\")\n",
                "print(\"=\"*60)\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"üìÅ Output: {DRIVE_OUTPUT_DIR}\")\n",
                "print(f\"üîÑ Resume: {do_resume}\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Comando\n",
                "cmd = f\"python scripts/train_weighted.py --config configs/training_config_weighted.yaml --data-csv {DATASET_CSV}\"\n",
                "if do_resume:\n",
                "    cmd += \" --resume\"\n",
                "\n",
                "!{cmd}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Valutazione"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5.1 Valutazione su SpeechOcean762\n",
                "MODEL_PATH = f\"{DRIVE_OUTPUT_DIR}/final_model_weighted\"\n",
                "\n",
                "if Path(MODEL_PATH).exists():\n",
                "    print(f\"üî¨ Valutazione modello: {MODEL_PATH}\")\n",
                "    !python scripts/05_evaluate_speechocean.py --model-path {MODEL_PATH}\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è Modello non trovato: {MODEL_PATH}\")\n",
                "    print(\"   Esegui prima il training!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5.2 Analisi Layer Weights (quali layer sono pi√π importanti)\n",
                "import torch\n",
                "import torch.nn.functional as F\n",
                "from pathlib import Path\n",
                "\n",
                "MODEL_PATH = f\"{DRIVE_OUTPUT_DIR}/final_model_weighted\"\n",
                "\n",
                "try:\n",
                "    # Carica il modello per vedere i pesi\n",
                "    checkpoint = torch.load(f\"{MODEL_PATH}/pytorch_model.bin\", map_location='cpu')\n",
                "    \n",
                "    if 'layer_weights' in checkpoint:\n",
                "        weights = checkpoint['layer_weights']\n",
                "        normalized = F.softmax(torch.tensor(weights), dim=0)\n",
                "        \n",
                "        print(\"üìä LAYER WEIGHTS (dopo training)\")\n",
                "        print(\"=\"*50)\n",
                "        for i, w in enumerate(normalized):\n",
                "            bar = \"‚ñà\" * int(w * 50)\n",
                "            print(f\"Layer {i:2d}: {w:.4f} {bar}\")\n",
                "        \n",
                "        print(f\"\\nüìä Layer pi√π importante: {normalized.argmax().item()}\")\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è layer_weights non trovato nel checkpoint\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è Errore caricamento: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Salvataggio Finale"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.1 Copia modello finale su Drive\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "\n",
                "LOCAL_MODEL = f\"{DRIVE_OUTPUT_DIR}/final_model_weighted\"\n",
                "DRIVE_FINAL = '/content/drive/MyDrive/phoneme_models/wavlm_weighted'\n",
                "\n",
                "if Path(LOCAL_MODEL).exists():\n",
                "    Path(DRIVE_FINAL).parent.mkdir(parents=True, exist_ok=True)\n",
                "    shutil.copytree(LOCAL_MODEL, DRIVE_FINAL, dirs_exist_ok=True)\n",
                "    print(f\"‚úÖ Modello copiato su: {DRIVE_FINAL}\")\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è Modello non trovato: {LOCAL_MODEL}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}