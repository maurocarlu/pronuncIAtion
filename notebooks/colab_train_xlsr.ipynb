{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üåç XLS-R Training (Modello Multilingua)\n",
                "\n",
                "Questo notebook addestra **XLS-R** (wav2vec2-xls-r-300m), un modello multilingua pre-addestrato su 128 lingue.\n",
                "\n",
                "**Perch√© XLS-R?**\n",
                "- Pre-training su 128 lingue ‚Üí variet√† fonetica maggiore\n",
                "- Complementa WavLM (focalizzato su inglese)\n",
                "- Ottimo per speaker non-nativi\n",
                "\n",
                "**‚ö†Ô∏è IMPORTANTE:**\n",
                "- XLS-R √® un modello grande (300M parametri)\n",
                "- Richiede ~12GB VRAM (usa T4 o migliore)\n",
                "- Training pi√π lento di WavLM (~2x)\n",
                "\n",
                "**üî¨ Per l'Ensemble:** Usa il notebook `colab_ensemble.ipynb` dopo aver trainato sia WavLM che XLS-R."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Ambiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.1 Verifica GPU\n",
                "!nvidia-smi\n",
                "\n",
                "import torch\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA disponibile: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    gpu_name = torch.cuda.get_device_name(0)\n",
                "    vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
                "    print(f\"GPU: {gpu_name}\")\n",
                "    print(f\"VRAM: {vram:.1f} GB\")\n",
                "    \n",
                "    if vram < 12:\n",
                "        print(\"\\n‚ö†Ô∏è ATTENZIONE: XLS-R richiede ~12GB VRAM\")\n",
                "        print(\"   Potrebbe essere necessario ridurre batch_size\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.2 Monta Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "print(\"‚úÖ Drive montato\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.3 Estrai progetto da zip\n",
                "import os\n",
                "import zipfile\n",
                "from pathlib import Path\n",
                "\n",
                "ZIP_PATH = '/content/drive/MyDrive/phonemeRef.zip'\n",
                "EXTRACT_PATH = '/content/DeepLearning-Phoneme'\n",
                "\n",
                "if not os.path.exists(ZIP_PATH):\n",
                "    raise FileNotFoundError(f\"‚ùå File non trovato: {ZIP_PATH}\\nCarica phonemeRef.zip su Google Drive\")\n",
                "\n",
                "print(f\"üì¶ Estrazione {ZIP_PATH}...\")\n",
                "with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
                "    zip_ref.extractall('/content/')\n",
                "\n",
                "# Trova cartella estratta\n",
                "extracted = [f for f in os.listdir('/content/') if os.path.isdir(f'/content/{f}') and 'Phoneme' in f]\n",
                "if extracted:\n",
                "    EXTRACT_PATH = f'/content/{extracted[0]}'\n",
                "\n",
                "os.chdir(EXTRACT_PATH)\n",
                "print(f\"‚úÖ Progetto in: {EXTRACT_PATH}\")\n",
                "!ls -la"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.4 Installa dipendenze\n",
                "!pip install -q transformers datasets evaluate jiwer accelerate soundfile librosa pyyaml tqdm audiomentations\n",
                "!pip install -q torchcodec\n",
                "print(\"\\n‚úÖ Dipendenze installate\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preparazione Dataset\n",
                "\n",
                "**‚ö†Ô∏è IMPORTANTE:** Usa lo stesso dataset di WavLM per l'ensemble!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.1 Carica e analizza dataset\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "\n",
                "# Opzioni dataset (DEVE essere lo stesso di WavLM!)\n",
                "DATASET_OPTIONS = [\n",
                "    'data/processed/combined_augmented.csv',\n",
                "    'data/processed/combined_dataset.csv',\n",
                "    'data/processed/phonemeref_processed.csv',\n",
                "]\n",
                "\n",
                "DATASET_CSV = None\n",
                "for opt in DATASET_OPTIONS:\n",
                "    if Path(opt).exists():\n",
                "        DATASET_CSV = opt\n",
                "        break\n",
                "\n",
                "if not DATASET_CSV:\n",
                "    raise FileNotFoundError(\"‚ùå Nessun dataset trovato!\")\n",
                "\n",
                "df = pd.read_csv(DATASET_CSV)\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"   Samples: {len(df):,}\")\n",
                "print(f\"\\n‚ö†Ô∏è IMPORTANTE: Usa lo stesso dataset di WavLM per l'ensemble!\")\n",
                "print(f\"\\n=== Distribuzione ===\")\n",
                "if 'source' in df.columns:\n",
                "    print(df['source'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.2 Verifica qualit√† IPA\n",
                "import pandas as pd\n",
                "import re\n",
                "\n",
                "df = pd.read_csv(DATASET_CSV)\n",
                "\n",
                "# 1. Cerca IPA invalidi (placeholder [word])\n",
                "placeholder_mask = df['ipa_clean'].str.contains(r'^\\[.*\\]$', regex=True, na=False)\n",
                "\n",
                "# 2. Cerca annotazioni problematiche\n",
                "annotation_mask = df['ipa_clean'].str.contains(\n",
                "    r'adj\\.|n\\.|v\\.|adv\\.|interj\\.|for \\d|unstressed|stressed|esp\\.|also|Brit\\.|;',\n",
                "    regex=True, na=False\n",
                ")\n",
                "\n",
                "# 3. IPA troppo corti\n",
                "short_mask = df['ipa_clean'].str.len() < 2\n",
                "\n",
                "invalid_mask = placeholder_mask | annotation_mask | short_mask\n",
                "invalid_count = invalid_mask.sum()\n",
                "\n",
                "print(f\"üîç Analisi qualit√† IPA:\")\n",
                "print(f\"   Totale samples: {len(df):,}\")\n",
                "print(f\"   IPA invalidi: {invalid_count:,} ({100*invalid_count/len(df):.1f}%)\")\n",
                "\n",
                "if invalid_count > 0:\n",
                "    df_clean = df[~invalid_mask].copy()\n",
                "    DATASET_CLEAN = 'data/processed/phonemeref_clean.csv'\n",
                "    df_clean.to_csv(DATASET_CLEAN, index=False)\n",
                "    print(f\"\\n‚úÖ Dataset pulito: {len(df_clean):,} samples\")\n",
                "    DATASET_CSV = DATASET_CLEAN\n",
                "else:\n",
                "    print(\"\\n‚úÖ Tutti gli IPA sono validi!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.3 Fix path e rimuovi file mancanti\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "\n",
                "df = pd.read_csv(DATASET_CSV)\n",
                "\n",
                "def fix_path(path_str):\n",
                "    path_str = str(path_str).replace('\\\\', '/')\n",
                "    if path_str.startswith('data/'):\n",
                "        return path_str\n",
                "    if path_str.startswith('audio/'):\n",
                "        return 'data/raw/phonemeref_data/' + path_str\n",
                "    if '/audio/' in path_str:\n",
                "        idx = path_str.find('/audio/')\n",
                "        return 'data/raw/phonemeref_data' + path_str[idx:]\n",
                "    if 'data/' in path_str:\n",
                "        idx = path_str.find('data/')\n",
                "        return path_str[idx:]\n",
                "    return path_str\n",
                "\n",
                "df['audio_path'] = df['audio_path'].apply(fix_path)\n",
                "\n",
                "# Verifica esistenza file\n",
                "print(\"üîç Verifica esistenza file audio...\")\n",
                "existing_mask = [Path(row['audio_path']).exists() for _, row in tqdm(df.iterrows(), total=len(df))]\n",
                "existing_mask = pd.Series(existing_mask, index=df.index)\n",
                "\n",
                "n_missing = (~existing_mask).sum()\n",
                "print(f\"\\nüìä File esistenti: {existing_mask.sum():,} / File mancanti: {n_missing:,}\")\n",
                "\n",
                "if n_missing > 0:\n",
                "    df = df[existing_mask].copy()\n",
                "    print(f\"‚úÖ Rimossi {n_missing} samples\")\n",
                "\n",
                "DATASET_FINAL = 'data/processed/phonemeref_ready.csv'\n",
                "df.to_csv(DATASET_FINAL, index=False)\n",
                "print(f\"\\n‚úÖ Dataset pronto: {DATASET_FINAL} ({len(df):,} samples)\")\n",
                "DATASET_CSV = DATASET_FINAL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.4 Verifica vocab.json\n",
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "vocab_path = Path('data/processed/vocab.json')\n",
                "if vocab_path.exists():\n",
                "    with open(vocab_path, encoding='utf-8') as f:\n",
                "        vocab = json.load(f)\n",
                "    print(f\"üìä Vocab: {len(vocab)} simboli\")\n",
                "    print(f\"‚úÖ Stesso vocab.json di WavLM - output allineati per ensemble\")\n",
                "else:\n",
                "    raise FileNotFoundError(\"‚ùå vocab.json non trovato!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configurazione Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.1 Configurazione (ottimizzata per XLS-R)\n",
                "import yaml\n",
                "import os\n",
                "\n",
                "DRIVE_OUTPUT_DIR = '/content/drive/MyDrive/phoneme_xlsr'\n",
                "\n",
                "config = {\n",
                "    'seed': 42,\n",
                "    'model': {\n",
                "        'name': 'facebook/wav2vec2-xls-r-300m',\n",
                "        'freeze_feature_encoder': True\n",
                "    },\n",
                "    'data': {\n",
                "        'csv_path': DATASET_CSV,\n",
                "        'vocab_path': 'data/processed/vocab.json',\n",
                "        'audio_base_path': '.',\n",
                "        'val_size': 0.05,\n",
                "        'test_size': 0.05,\n",
                "        'sampling_rate': 16000\n",
                "    },\n",
                "    'training': {\n",
                "        'output_dir': DRIVE_OUTPUT_DIR,\n",
                "        'num_train_epochs': 10,\n",
                "        'per_device_train_batch_size': 4,\n",
                "        'per_device_eval_batch_size': 4,\n",
                "        'gradient_accumulation_steps': 4,\n",
                "        'learning_rate': 3e-5,\n",
                "        'warmup_steps': 500,\n",
                "        'weight_decay': 0.01,\n",
                "        'fp16': True,\n",
                "        'gradient_checkpointing': True,\n",
                "    }\n",
                "}\n",
                "\n",
                "os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "with open('configs/training_config_xlsr.yaml', 'w') as f:\n",
                "    yaml.dump(config, f, default_flow_style=False)\n",
                "\n",
                "print(f\"üìÅ Output: {DRIVE_OUTPUT_DIR}\")\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"üî¢ Epochs: {config['training']['num_train_epochs']}\")\n",
                "print(f\"üì¶ Batch: {config['training']['per_device_train_batch_size']} x {config['training']['gradient_accumulation_steps']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.2 Verifica checkpoint esistenti\n",
                "from pathlib import Path\n",
                "import json\n",
                "\n",
                "output_dir = Path(DRIVE_OUTPUT_DIR)\n",
                "checkpoints = []\n",
                "\n",
                "if output_dir.exists():\n",
                "    checkpoints = sorted([\n",
                "        d for d in output_dir.iterdir() \n",
                "        if d.is_dir() and d.name.startswith(\"checkpoint-\")\n",
                "    ])\n",
                "\n",
                "print(f\"üìÅ Output: {output_dir}\")\n",
                "if checkpoints:\n",
                "    print(f\"‚úÖ {len(checkpoints)} checkpoint trovati\")\n",
                "    for cp in checkpoints[-3:]:\n",
                "        state_file = cp / \"trainer_state.json\"\n",
                "        if state_file.exists():\n",
                "            with open(state_file) as f:\n",
                "                state = json.load(f)\n",
                "            print(f\"   üìÅ {cp.name}: Epoch {state.get('epoch', '?')}, PER {state.get('best_metric', '?'):.4f}\")\n",
                "else:\n",
                "    print(\"‚ùå Nessun checkpoint - Training da zero\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.1 Avvia Training XLS-R\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
                "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
                "\n",
                "RESUME = \"auto\"  # True, False, o \"auto\"\n",
                "\n",
                "drive_path = Path(DRIVE_OUTPUT_DIR)\n",
                "existing_checkpoints = sorted([\n",
                "    d for d in drive_path.iterdir() \n",
                "    if d.is_dir() and d.name.startswith(\"checkpoint-\")\n",
                "]) if drive_path.exists() else []\n",
                "\n",
                "do_resume = len(existing_checkpoints) > 0 if RESUME == \"auto\" else bool(RESUME)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üöÄ AVVIO TRAINING XLS-R\")\n",
                "print(\"=\"*60)\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"üìÅ Output: {DRIVE_OUTPUT_DIR}\")\n",
                "print(f\"üîÑ Resume: {do_resume}\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "cmd = f\"python scripts/training/train_xlsr.py --config configs/training_config_xlsr.yaml --data-csv {DATASET_CSV}\"\n",
                "if do_resume:\n",
                "    cmd += \" --resume\"\n",
                "\n",
                "!{cmd}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Valutazione"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5.1 Visualizza curve di training\n",
                "import json\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "\n",
                "state_path = None\n",
                "for loc in [\n",
                "    Path(DRIVE_OUTPUT_DIR) / 'final_model_xlsr' / 'trainer_state.json',\n",
                "    Path(DRIVE_OUTPUT_DIR) / 'trainer_state.json',\n",
                "]:\n",
                "    if loc.exists():\n",
                "        state_path = loc\n",
                "        break\n",
                "\n",
                "if not state_path:\n",
                "    checkpoints = sorted([\n",
                "        d for d in Path(DRIVE_OUTPUT_DIR).iterdir() \n",
                "        if d.is_dir() and d.name.startswith(\"checkpoint-\")\n",
                "    ]) if Path(DRIVE_OUTPUT_DIR).exists() else []\n",
                "    if checkpoints:\n",
                "        state_path = checkpoints[-1] / 'trainer_state.json'\n",
                "\n",
                "if state_path and state_path.exists():\n",
                "    with open(state_path) as f:\n",
                "        state = json.load(f)\n",
                "    \n",
                "    log_history = state.get('log_history', [])\n",
                "    train_loss = [(h['step'], h['loss']) for h in log_history if 'loss' in h and 'eval_loss' not in h]\n",
                "    eval_per = [(h['step'], h['eval_per']) for h in log_history if 'eval_per' in h]\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "    \n",
                "    if train_loss:\n",
                "        steps, losses = zip(*train_loss)\n",
                "        axes[0].plot(steps, losses, 'b-', alpha=0.7)\n",
                "        axes[0].set_title('Training Loss')\n",
                "        axes[0].grid(True)\n",
                "    \n",
                "    if eval_per:\n",
                "        steps, pers = zip(*eval_per)\n",
                "        axes[1].plot(steps, [p*100 for p in pers], 'g-o')\n",
                "        axes[1].set_title('PER (%)')\n",
                "        axes[1].grid(True)\n",
                "        print(f\"üèÜ Best PER: {min(pers)*100:.2f}%\")\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f'{DRIVE_OUTPUT_DIR}/training_curves.png', dpi=150)\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"‚ùå trainer_state.json non trovato\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5.2 Valutazione su SpeechOcean762\n",
                "from pathlib import Path\n",
                "\n",
                "MODEL_PATH = f\"{DRIVE_OUTPUT_DIR}/final_model_xlsr\"\n",
                "\n",
                "if Path(MODEL_PATH).exists():\n",
                "    print(f\"üî¨ Valutazione modello XLS-R: {MODEL_PATH}\")\n",
                "    !python scripts/evaluation/evaluate_speechocean.py --model-path {MODEL_PATH}\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è Modello non trovato: {MODEL_PATH}\")\n",
                "    print(\"   Esegui prima il training!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Salvataggio Finale"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.1 Verifica contenuto su Drive\n",
                "from pathlib import Path\n",
                "\n",
                "print(f\"üìÅ CONTENUTO: {DRIVE_OUTPUT_DIR}\")\n",
                "print(\"-\"*50)\n",
                "\n",
                "drive_path = Path(DRIVE_OUTPUT_DIR)\n",
                "if drive_path.exists():\n",
                "    for item in sorted(drive_path.iterdir()):\n",
                "        if item.is_dir():\n",
                "            n_files = len(list(item.rglob(\"*\")))\n",
                "            print(f\"  üìÅ {item.name}/ ({n_files} files)\")\n",
                "        else:\n",
                "            size_mb = item.stat().st_size / 1e6\n",
                "            print(f\"  üìÑ {item.name} ({size_mb:.1f} MB)\")\n",
                "\n",
                "    if (drive_path / \"final_model_xlsr\").exists():\n",
                "        print(\"\\n‚úÖ Modello finale presente!\")\n",
                "    else:\n",
                "        print(\"\\n‚ö†Ô∏è Modello finale non trovato\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.2 Crea zip per download\n",
                "import os\n",
                "\n",
                "FINAL_MODEL = f'{DRIVE_OUTPUT_DIR}/final_model_xlsr'\n",
                "ZIP_PATH = f'{DRIVE_OUTPUT_DIR}/final_model_xlsr.zip'\n",
                "\n",
                "if os.path.exists(FINAL_MODEL):\n",
                "    !cd {FINAL_MODEL} && zip -r {ZIP_PATH} .\n",
                "    print(f\"\\n‚úÖ Zip creato: {ZIP_PATH}\")\n",
                "    !ls -lh {ZIP_PATH}\n",
                "else:\n",
                "    print(\"‚ùå Modello finale non trovato\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üéâ Fine\n",
                "\n",
                "Modello salvato su Google Drive:\n",
                "- `final_model_xlsr/` - Modello trainato\n",
                "- `final_model_xlsr.zip` - Per download\n",
                "\n",
                "**Prossimo passo:** Usa `colab_ensemble.ipynb` per Late Fusion con WavLM!"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
