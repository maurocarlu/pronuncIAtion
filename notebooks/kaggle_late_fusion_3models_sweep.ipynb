{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2ae7b4",
   "metadata": {},
   "source": [
    "# üß™ Kaggle Late Fusion Sweep (3 modelli) ‚Äî SpeechOcean762\n",
    "\n",
    "Questo notebook:\n",
    "- carica **3 modelli CTC** da uno **ZIP** (Kaggle Dataset input)\n",
    "- esegue **Late Fusion** solo su **coppie** e sulla **tripla** (niente valutazione dei singoli)\n",
    "- sweep su griglie di pesi (step configurabile)\n",
    "- valuta su **SpeechOcean762** con i 3 task (A/B/C)\n",
    "- salva **una riga per ogni configurazione** in Excel (append)\n",
    "\n",
    "Nota: i 3 modelli devono condividere lo stesso tokenizer/vocab (stesso mapping token‚Üíid).\n",
    "Se includi **WavLM Large**, usa la versione *non weighted* come richiesto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5426bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install deps (Kaggle) + clone repo (per confronto affidabile)\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- deps ----\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q',\n",
    "                'transformers>=4.38', 'datasets>=2.18', 'jiwer',\n",
    "                'soundfile', 'librosa', 'scikit-learn', 'scipy', 'safetensors',\n",
    "                'openpyxl', 'accelerate', 'tqdm'], check=False)\n",
    "\n",
    "import zipfile, math\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print('torch:', torch.__version__, 'cuda:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('gpu:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# ---- clone repo (default ON su Kaggle) ----\n",
    "IS_KAGGLE = Path('/kaggle').exists()\n",
    "SKIP_CLONE = str(os.environ.get('DL_PHONEME_SKIP_CLONE', '')).strip().lower() in ('1', 'true', 'yes')\n",
    "\n",
    "REPO_URL_DEFAULT = 'https://github.com/maurocarlu/pronuncIAtion.git'\n",
    "REPO_URL = str(os.environ.get('DL_PHONEME_REPO_URL', REPO_URL_DEFAULT)).strip()\n",
    "\n",
    "# Nota: su Kaggle cloniamo per usare ESATTAMENTE le stesse funzioni di normalizzazione/mapping\n",
    "PROJECT_DIR = (Path('/kaggle/working/pronuncIAtion') if IS_KAGGLE else Path.cwd())\n",
    "\n",
    "if IS_KAGGLE and (not SKIP_CLONE) and REPO_URL:\n",
    "    if not PROJECT_DIR.exists():\n",
    "        print('Cloning repo:', REPO_URL)\n",
    "        subprocess.run(['git', 'clone', REPO_URL, str(PROJECT_DIR)], check=False)\n",
    "    else:\n",
    "        print('Repo gi√† presente:', PROJECT_DIR)\n",
    "\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "    os.chdir(PROJECT_DIR)\n",
    "    print('CWD:', os.getcwd())\n",
    "else:\n",
    "    if IS_KAGGLE and SKIP_CLONE:\n",
    "        print('Repo clone skipped (DL_PHONEME_SKIP_CLONE=1).')\n",
    "    else:\n",
    "        print('Repo clone skipped (not running on Kaggle).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG ‚Äî modifica questi parametri\n",
    "KAGGLE_INPUT_DATASET_DIR = '/kaggle/input'\n",
    "ZIP_DATASET_NAME = 'late-fusion'   # <-- dataset Kaggle che contiene lo zip\n",
    "ZIP_FILENAME = 'LateFusion'                    # <-- nome file zip o directory montata\n",
    "\n",
    "# Valutazione\n",
    "FULL_DATASET = True   # True = ~2500 esempi\n",
    "MAX_SAMPLES = None    # es. 300 per debug\n",
    "BATCH_SIZE = 4\n",
    "WEIGHT_STEP = 0.10    # 0.10 (veloce) / 0.05 (pi√π fine ma pi√π lenta)\n",
    "\n",
    "# Benchmark logging (schema compatibile con scripts/evaluation/track_benchmark.py)\n",
    "TRAINING_DATA = 'Aug_Comb'\n",
    "ARCHITECTURE = 'Fusion'  # valori ammessi: ... 'Fusion'\n",
    "MODEL_NAME_PREFIX = 'LateFusion'\n",
    "\n",
    "# Output\n",
    "EXTRACT_DIR = Path('/kaggle/working/models_extracted')\n",
    "BENCHMARK_XLSX = (PROJECT_DIR / 'benchmark_results.xlsx') if IS_KAGGLE else Path('benchmark_results.xlsx')\n",
    "OUTPUT_XLSX = BENCHMARK_XLSX\n",
    "ZIP_PATH = Path(KAGGLE_INPUT_DATASET_DIR) / ZIP_DATASET_NAME / ZIP_FILENAME\n",
    "\n",
    "print('ZIP_PATH:', ZIP_PATH)\n",
    "print('Exists:', ZIP_PATH.exists())\n",
    "print('OUTPUT_XLSX (track_benchmark schema):', OUTPUT_XLSX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96007bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai lo ZIP dei modelli (o usa direttamente la directory) e individua le cartelle modello\n",
    "EXTRACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "assert ZIP_PATH.exists(), f'Percorso non trovato: {ZIP_PATH}. Controlla ZIP_DATASET_NAME / ZIP_FILENAME.'\n",
    "\n",
    "# Kaggle a volte monta direttamente una CARTELLA invece di un .zip: gestiamo entrambi\n",
    "if ZIP_PATH.is_dir():\n",
    "    print('‚ÑπÔ∏è ZIP_PATH √® una directory. Salto estrazione zip e uso direttamente questa directory.')\n",
    "    MODELS_ROOT = ZIP_PATH\n",
    "else:\n",
    "    MODELS_ROOT = EXTRACT_DIR\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n",
    "        z.extractall(EXTRACT_DIR)\n",
    "    print('‚úì Extracted to:', EXTRACT_DIR)\n",
    "\n",
    "# Trova directory che contengono config.json (modelli HF)\n",
    "candidate_model_dirs = sorted({p.parent for p in MODELS_ROOT.glob('**/config.json')})\n",
    "print(f'Found {len(candidate_model_dirs)} candidate model dirs')\n",
    "for p in candidate_model_dirs[:30]:\n",
    "    print('  ‚úì', p)\n",
    "if len(candidate_model_dirs) > 30:\n",
    "    print('  ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selezione model dirs (AUTO se possibile, altrimenti manuale)\n",
    "# Nota: qui vuoi includere WavLM Large (non weighted) come uno dei 3 modelli.\n",
    "\n",
    "MODEL_DIRS = None\n",
    "if len(candidate_model_dirs) == 3:\n",
    "    MODEL_DIRS = [str(p) for p in candidate_model_dirs]\n",
    "elif len(candidate_model_dirs) > 3:\n",
    "    # euristica: prendi le ultime 3 (spesso i final_model stanno pi√π in profondit√†)\n",
    "    MODEL_DIRS = [str(p) for p in candidate_model_dirs[-3:]]\n",
    "\n",
    "# Se vuoi forzare manualmente, decommenta e modifica:\n",
    "# MODEL_DIRS = [\n",
    "#   str(MODELS_ROOT / 'hubert_large' / 'final_model_hubert'),\n",
    "#   str(MODELS_ROOT / 'wavLM_large' / 'final_model_wavlm_large'),\n",
    "#   str(MODELS_ROOT / 'wav2vec2_phoneme' / 'final_model'),\n",
    "# ]\n",
    "\n",
    "assert MODEL_DIRS is not None and len(MODEL_DIRS) == 3, (\n",
    "    'Imposta MODEL_DIRS manualmente: nello zip/directory ci sono !=3 cartelle modello.'\n",
    " )\n",
    "\n",
    "for i, p in enumerate(MODEL_DIRS, start=1):\n",
    "    p = Path(p)\n",
    "    has_config = (p / 'config.json').exists()\n",
    "    print(f'Model {i}: {p} | exists={p.exists()} | has_config={has_config}')\n",
    "    assert p.exists() and has_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper audio decode + metriche (ALLINEATI alla repo: normalize_ipa / arpa_to_ipa)\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "# --- importa util dal progetto (se repo clonata su Kaggle o se stai eseguendo dentro la repo) ---\n",
    "try:\n",
    "    from src.data.normalize_ipa import IPANormalizer, arpa_to_ipa\n",
    "    _HAS_PROJECT_NORMALIZER = True\n",
    "except Exception as e:\n",
    "    _HAS_PROJECT_NORMALIZER = False\n",
    "    IPANormalizer = None\n",
    "    arpa_to_ipa = None\n",
    "    print('‚ö†Ô∏è Impossibile importare src.data.normalize_ipa:', repr(e))\n",
    "    print('   Fallback: normalizzazione semplice + mapping ARPA_TO_IPA minimale (meno affidabile).')\n",
    "\n",
    "def _to_mono_float32(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 1:\n",
    "        out = arr\n",
    "    elif arr.ndim == 2:\n",
    "        if arr.shape[0] <= 8 and arr.shape[1] > arr.shape[0]:\n",
    "            out = arr.mean(axis=0)\n",
    "        elif arr.shape[1] <= 8:\n",
    "            out = arr.mean(axis=1)\n",
    "        else:\n",
    "            out = arr.reshape(-1)\n",
    "    else:\n",
    "        out = arr.reshape(-1)\n",
    "    return out.astype(np.float32, copy=False)\n",
    "\n",
    "def _resample_1d(arr: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:\n",
    "    if int(orig_sr) == int(target_sr):\n",
    "        return arr.astype(np.float32, copy=False)\n",
    "    try:\n",
    "        import librosa\n",
    "        return librosa.resample(arr.astype(np.float32, copy=False), orig_sr=orig_sr, target_sr=target_sr).astype(np.float32)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        from scipy.signal import resample_poly\n",
    "        g = math.gcd(int(orig_sr), int(target_sr))\n",
    "        up = int(target_sr) // g\n",
    "        down = int(orig_sr) // g\n",
    "        return resample_poly(arr, up=up, down=down).astype(np.float32)\n",
    "    except Exception:\n",
    "        ratio = float(target_sr) / float(orig_sr)\n",
    "        n = int(max(1, round(len(arr) * ratio)))\n",
    "        x_old = np.linspace(0.0, 1.0, num=len(arr), endpoint=False)\n",
    "        x_new = np.linspace(0.0, 1.0, num=n, endpoint=False)\n",
    "        return np.interp(x_new, x_old, arr).astype(np.float32)\n",
    "\n",
    "def _decode_audio_dict_payload(audio_dict: dict):\n",
    "    \"\"\"Gestisce payload HF datasets quando usi Audio(decode=False).\"\"\"\n",
    "    import soundfile as sf\n",
    "    # 1) preferisci bytes (Kaggle spesso li usa)\n",
    "    b = audio_dict.get('bytes', None)\n",
    "    if b is not None:\n",
    "        if isinstance(b, memoryview):\n",
    "            b = b.tobytes()\n",
    "        arr, sr = sf.read(io.BytesIO(b), dtype='float32', always_2d=False)\n",
    "        return arr, int(sr)\n",
    "    # 2) fallback: path (locale o remoto)\n",
    "    p = audio_dict.get('path', None)\n",
    "    if p is None:\n",
    "        raise ValueError(f\"Audio dict senza 'bytes' e senza 'path': keys={list(audio_dict.keys())}\")\n",
    "    p = str(p)\n",
    "    if os.path.exists(p):\n",
    "        arr, sr = sf.read(p, dtype='float32', always_2d=False)\n",
    "        return arr, int(sr)\n",
    "    # 3) prova a leggere via fsspec (es. hf:// o path non locale)\n",
    "    try:\n",
    "        import fsspec\n",
    "        with fsspec.open(p, 'rb') as f:\n",
    "            data = f.read()\n",
    "        arr, sr = sf.read(io.BytesIO(data), dtype='float32', always_2d=False)\n",
    "        return arr, int(sr)\n",
    "    except Exception as e:\n",
    "        raise FileNotFoundError(f\"Audio path non leggibile: {p} ({e})\")\n",
    "\n",
    "def decode_audio_to_16k(audio_data, target_sr: int = 16000):\n",
    "    arr = None\n",
    "    sr = target_sr\n",
    "    if isinstance(audio_data, dict):\n",
    "        # HF Audio(decode=False) tipicamente: {'path': ..., 'bytes': ..., 'sampling_rate': ...?}\n",
    "        if audio_data.get('array') is not None:\n",
    "            arr = audio_data['array']\n",
    "            sr = int(audio_data.get('sampling_rate', target_sr) or target_sr)\n",
    "        else:\n",
    "            arr, sr = _decode_audio_dict_payload(audio_data)\n",
    "    elif hasattr(audio_data, 'get_all_samples'):\n",
    "        samples = audio_data.get_all_samples()\n",
    "        sr = int(getattr(samples, 'sample_rate', getattr(samples, 'sampling_rate', target_sr)) or target_sr)\n",
    "        data = getattr(samples, 'data', samples)\n",
    "        arr = data.numpy() if hasattr(data, 'numpy') else np.asarray(data)\n",
    "    elif hasattr(audio_data, 'array'):\n",
    "        arr = np.asarray(audio_data.array)\n",
    "        sr = int(getattr(audio_data, 'sampling_rate', target_sr) or target_sr)\n",
    "    elif callable(audio_data):\n",
    "        decoded = audio_data()\n",
    "        data = getattr(decoded, 'data', decoded)\n",
    "        arr = data.numpy() if hasattr(data, 'numpy') else np.asarray(data)\n",
    "        sr = int(getattr(decoded, 'sample_rate', getattr(decoded, 'sampling_rate', target_sr)) or target_sr)\n",
    "    else:\n",
    "        import soundfile as sf\n",
    "        arr, sr = sf.read(str(audio_data), dtype='float32', always_2d=False)\n",
    "    if arr is None:\n",
    "        raise ValueError(f'Audio payload non decodificabile: {type(audio_data)}')\n",
    "    arr = _to_mono_float32(arr)\n",
    "    if int(sr) != int(target_sr):\n",
    "        arr = _resample_1d(arr, int(sr), int(target_sr))\n",
    "        sr = target_sr\n",
    "    return arr, int(sr)\n",
    "\n",
    "# --- reference IPA: usa la conversione ARPA‚ÜíIPA del progetto ---\n",
    "ARPA_TO_IPA_FALLBACK = {\n",
    "    'AA':'…ë','AE':'√¶','AH':' å','AO':'…î','AW':'a ä','AY':'a…™',\n",
    "    'B':'b','CH':'t É','D':'d','DH':'√∞','EH':'…õ','ER':'…ù','EY':'e…™',\n",
    "    'F':'f','G':'…°','HH':'h','IH':'…™','IY':'i','JH':'d í',\n",
    "    'K':'k','L':'l','M':'m','N':'n','NG':'≈ã','OW':'o ä','OY':'…î…™',\n",
    "    'P':'p','R':'…π','S':'s','SH':' É','T':'t','TH':'Œ∏','UH':' ä','UW':'u',\n",
    "    'V':'v','W':'w','Y':'j','Z':'z','ZH':' í',\n",
    "}\n",
    "\n",
    "def _arpa_to_ipa_fallback(phone: str) -> str:\n",
    "    if phone is None:\n",
    "        return ''\n",
    "    p = str(phone).strip().upper()\n",
    "    while p and p[-1].isdigit():\n",
    "        p = p[:-1]\n",
    "    return ARPA_TO_IPA_FALLBACK.get(p, '')\n",
    "\n",
    "def extract_phones_from_words(words_list) -> str:\n",
    "    out = []\n",
    "    for w in (words_list or []):\n",
    "        for p in (w.get('phones', []) or []):\n",
    "            if _HAS_PROJECT_NORMALIZER and arpa_to_ipa is not None:\n",
    "                ipa = arpa_to_ipa(p, use_corrected=True)\n",
    "            else:\n",
    "                ipa = _arpa_to_ipa_fallback(p)\n",
    "            if ipa:\n",
    "                out.append(ipa)\n",
    "    return ''.join(out)\n",
    "\n",
    "# --- normalizzazione + CER/PER (coerente con scripts/evaluation/evaluate_speechocean.py) ---\n",
    "normalizer = IPANormalizer(mode='strict') if _HAS_PROJECT_NORMALIZER and IPANormalizer is not None else None\n",
    "\n",
    "def normalize_for_eval(s: str) -> str:\n",
    "    s = '' if s is None else str(s)\n",
    "    if normalizer is None:\n",
    "        # fallback minimale (meno fedele alla repo)\n",
    "        s = s.strip().replace(' ', '')\n",
    "        for ch in ['Àà','Àå','Àê','¬∑']:\n",
    "            s = s.replace(ch, '')\n",
    "        return s\n",
    "    return normalizer.normalize(s)\n",
    "\n",
    "def levenshtein(a: str, b: str) -> int:\n",
    "    if a == b:\n",
    "        return 0\n",
    "    if not a:\n",
    "        return len(b)\n",
    "    if not b:\n",
    "        return len(a)\n",
    "    prev = list(range(len(b) + 1))\n",
    "    for i, ca in enumerate(a, start=1):\n",
    "        cur = [i]\n",
    "        for j, cb in enumerate(b, start=1):\n",
    "            ins = cur[j-1] + 1\n",
    "            dele = prev[j] + 1\n",
    "            sub = prev[j-1] + (0 if ca == cb else 1)\n",
    "            cur.append(min(ins, dele, sub))\n",
    "        prev = cur\n",
    "    return prev[-1]\n",
    "\n",
    "def cer_components(pred: str, ref: str):\n",
    "    pred = pred or ''\n",
    "    ref = ref or ''\n",
    "    return levenshtein(pred, ref), len(ref)\n",
    "\n",
    "def cer(pred: str, ref: str) -> float:\n",
    "    e, n = cer_components(pred, ref)\n",
    "    return float(e) / float(max(1, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset SpeechOcean762 + prepara reference IPA (evita torchcodec con decode=False)\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "ds_dict = load_dataset('mispeech/speechocean762')\n",
    "split_name = 'test' if 'test' in ds_dict else ('validation' if 'validation' in ds_dict else list(ds_dict.keys())[0])\n",
    "ds = ds_dict[split_name]\n",
    "print('Loaded split:', split_name, 'len=', len(ds))\n",
    "\n",
    "# IMPORTANT: disabilita decode automatico dell'audio (cos√¨ non serve torchcodec)\n",
    "if 'audio' in ds.column_names:\n",
    "    ds = ds.cast_column('audio', Audio(decode=False))\n",
    "    print('‚úì audio casted to decode=False')\n",
    "\n",
    "if not FULL_DATASET:\n",
    "    ds = ds.select(range(min(500, len(ds))))\n",
    "if MAX_SAMPLES is not None:\n",
    "    ds = ds.select(range(min(int(MAX_SAMPLES), len(ds))))\n",
    "\n",
    "refs = []\n",
    "human_scores = []\n",
    "texts = []\n",
    "valid_indices = []\n",
    "\n",
    "for i in range(len(ds)):\n",
    "    ex = ds[i]\n",
    "    ref_ipa = extract_phones_from_words(ex.get('words', []))\n",
    "    score = ex.get('accuracy', ex.get('score', None))\n",
    "    text = ex.get('text', ex.get('sentence', ex.get('prompt', '')))\n",
    "\n",
    "    refs.append(ref_ipa)\n",
    "    human_scores.append(float(score) if score is not None else float('nan'))\n",
    "    texts.append(text)\n",
    "\n",
    "    # Per confronto affidabile: richiediamo reference + score\n",
    "    if ref_ipa and score is not None:\n",
    "        valid_indices.append(i)\n",
    "\n",
    "print('Valid examples for eval:', len(valid_indices), '/', len(ds))\n",
    "assert len(valid_indices) > 0, 'Nessun esempio valido: controlla colonne (words/accuracy).'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7776920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 3 models + processors\n",
    "from transformers import AutoModelForCTC, AutoProcessor\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "processors = []\n",
    "models = []\n",
    "model_names = []\n",
    "\n",
    "for p in MODEL_DIRS:\n",
    "    p = str(p)\n",
    "    proc = AutoProcessor.from_pretrained(p)\n",
    "    m = AutoModelForCTC.from_pretrained(p, torch_dtype=dtype)\n",
    "    m.to(device)\n",
    "    m.eval()\n",
    "    processors.append(proc)\n",
    "    models.append(m)\n",
    "    model_names.append(Path(p).name)\n",
    "    print('‚úì loaded:', p)\n",
    "\n",
    "def _get_vocab(proc):\n",
    "    tok = getattr(proc, 'tokenizer', None)\n",
    "    if tok is None:\n",
    "        return None\n",
    "    try:\n",
    "        return tok.get_vocab()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "vocabs = [_get_vocab(p) for p in processors]\n",
    "if all(v is not None for v in vocabs):\n",
    "    base = vocabs[0]\n",
    "    for i, v in enumerate(vocabs[1:], start=2):\n",
    "        if base != v:\n",
    "            raise RuntimeError(f'Vocab mismatch tra model 1 e model {i}. Late fusion richiede stesso mapping token->id.')\n",
    "    print('‚úì tokenizer vocabs match')\n",
    "else:\n",
    "    print('‚ö†Ô∏è Non posso verificare vocab con certezza. Assicurati che i 3 modelli usino lo stesso vocab.json/tokenizer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad030d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera combinazioni pesi: SOLO coppie + tripla (no singoli)\n",
    "def generate_weight_combos(step: float):\n",
    "    assert 0 < step < 1\n",
    "    steps = int(round(1.0 / step))\n",
    "    if abs(steps * step - 1.0) > 1e-6:\n",
    "        raise ValueError('WEIGHT_STEP deve dividere 1.0 esattamente (es. 0.1, 0.05).')\n",
    "\n",
    "    combos = []\n",
    "\n",
    "    # Coppie: (a, 1-a, 0) ecc, escludendo a=0/1 (singoli)\n",
    "    alphas = [i * step for i in range(1, steps)]\n",
    "    pairs = [(0,1,2), (0,2,1), (1,2,0)]\n",
    "    for a in alphas:\n",
    "        if a <= 0.0 or a >= 1.0:\n",
    "            continue\n",
    "        for i,j,k in pairs:\n",
    "            w = [0.0, 0.0, 0.0]\n",
    "            w[i] = float(a)\n",
    "            w[j] = float(1.0 - a)\n",
    "            w[k] = 0.0\n",
    "            combos.append(tuple(w))\n",
    "\n",
    "    # Tripla: griglia sul simplex con tutti i pesi > 0\n",
    "    for i in range(1, steps):\n",
    "        for j in range(1, steps - i):\n",
    "            k = steps - i - j\n",
    "            if k <= 0:\n",
    "                continue\n",
    "            w1 = i / steps\n",
    "            w2 = j / steps\n",
    "            w3 = k / steps\n",
    "            combos.append((w1, w2, w3))\n",
    "\n",
    "    # Dedup conservando ordine\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for c in combos:\n",
    "        key = tuple(round(x, 6) for x in c)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        unique.append(c)\n",
    "    return unique\n",
    "\n",
    "weight_combos = generate_weight_combos(WEIGHT_STEP)\n",
    "print('weight combos:', len(weight_combos))\n",
    "print('example:', weight_combos[:5])\n",
    "\n",
    "human_valid = np.array([human_scores[i] for i in valid_indices], dtype=np.float32)\n",
    "refs_valid = [refs[i] for i in valid_indices]\n",
    "\n",
    "acc = {c: {'pers': [], 'hq_edits': 0, 'hq_chars': 0} for c in weight_combos}\n",
    "decode_failures = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference loop: forward una volta per batch per modello, poi sweep pesi sul batch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def _batch(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "decode_failures = 0\n",
    "first_decode_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_ids in tqdm(list(_batch(valid_indices, BATCH_SIZE))):\n",
    "        audios = []\n",
    "        ok = []\n",
    "        for idx in batch_ids:\n",
    "            try:\n",
    "                arr, _ = decode_audio_to_16k(ds[int(idx)]['audio'], 16000)\n",
    "                audios.append(arr)\n",
    "                ok.append(True)\n",
    "            except Exception as e:\n",
    "                audios.append(np.zeros(16000, dtype=np.float32))\n",
    "                ok.append(False)\n",
    "                decode_failures += 1\n",
    "                if len(first_decode_errors) < 5:\n",
    "                    payload = ds[int(idx)]['audio']\n",
    "                    keys = list(payload.keys()) if isinstance(payload, dict) else None\n",
    "                    first_decode_errors.append((int(idx), type(payload).__name__, keys, repr(e)))\n",
    "\n",
    "        logits_list = []\n",
    "        for proc, model in zip(processors, models):\n",
    "            inputs = proc(audios, sampling_rate=16000, return_tensors='pt', padding=True)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            out = model(**inputs)\n",
    "            logits_list.append(out.logits)\n",
    "\n",
    "        # allinea tempo (T) tra modelli\n",
    "        min_t = min(l.shape[1] for l in logits_list)\n",
    "        logits_list = [l[:, :min_t, :].float() for l in logits_list]\n",
    "\n",
    "        ref_batch_raw = [refs[int(i)] for i in batch_ids]\n",
    "        score_batch = [human_scores[int(i)] for i in batch_ids]\n",
    "\n",
    "        for combo in weight_combos:\n",
    "            w1, w2, w3 = combo\n",
    "            fused = logits_list[0] * float(w1)\n",
    "            fused = fused + logits_list[1] * float(w2)\n",
    "            fused = fused + logits_list[2] * float(w3)\n",
    "\n",
    "            pred_ids = fused.argmax(dim=-1)\n",
    "            pred_texts = processors[0].batch_decode(pred_ids)\n",
    "\n",
    "            for p_raw, r_raw, s, ok_i in zip(pred_texts, ref_batch_raw, score_batch, ok):\n",
    "                # Normalizzazione allineata al progetto\n",
    "                r = normalize_for_eval(r_raw)\n",
    "                if not r:\n",
    "                    acc[combo]['pers'].append(1.0)\n",
    "                    continue\n",
    "                if not ok_i:\n",
    "                    p = ''\n",
    "                    per_i = 1.0\n",
    "                else:\n",
    "                    p = normalize_for_eval(p_raw)\n",
    "                    per_i = cer(p, r)\n",
    "\n",
    "                acc[combo]['pers'].append(float(per_i))\n",
    "\n",
    "                # Task A: high quality score >= 8\n",
    "                if float(s) >= 8.0:\n",
    "                    e, n = cer_components('' if not ok_i else p, r)\n",
    "                    acc[combo]['hq_edits'] += int(e)\n",
    "                    acc[combo]['hq_chars'] += int(n)\n",
    "\n",
    "print('decode failures:', decode_failures)\n",
    "if first_decode_errors:\n",
    "    print('First decode errors (up to 5):')\n",
    "    for idx, typ, keys, err in first_decode_errors:\n",
    "        print('  - idx=', idx, '| type=', typ, '| keys=', keys, '| err=', err)\n",
    "n_valid = len(valid_indices)\n",
    "for c in weight_combos:\n",
    "    len_p = len(acc[c]['pers'])\n",
    "    assert len_p == n_valid, f'Length mismatch for combo {c}: {len_p} vs {n_valid}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8bdc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola metriche Task A/B/C e append su Excel (schema ALLINEATO a scripts/evaluation/track_benchmark.py)\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "TRACK_BENCHMARK_COLUMNS = [\n",
    "    'Model_Name',\n",
    "    'Architecture',\n",
    "    'Training_Data',\n",
    "    'TaskA_PER_HighQuality',\n",
    "    'TaskA_Accuracy',\n",
    "    'TaskB_Pearson_r',\n",
    "    'TaskB_Spearman_rho',\n",
    "    'TaskC_AUC_ROC',\n",
    "    'TaskC_F1_Score',\n",
    "    'TaskC_Recall_Errors',\n",
    "    'TaskC_Precision',\n",
    "    'TaskC_Threshold',\n",
    "    'Notes',\n",
    " ]\n",
    "\n",
    "def append_row_track_benchmark_xlsx(path: Path, row: dict, sheet_name: str = 'Benchmark Results'):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if path.exists():\n",
    "        try:\n",
    "            df = pd.read_excel(path, engine='openpyxl')\n",
    "        except Exception:\n",
    "            df = pd.DataFrame(columns=TRACK_BENCHMARK_COLUMNS)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=TRACK_BENCHMARK_COLUMNS)\n",
    "\n",
    "    # garantisci colonne\n",
    "    for col in TRACK_BENCHMARK_COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    df = df[TRACK_BENCHMARK_COLUMNS]\n",
    "\n",
    "    # append\n",
    "    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    with pd.ExcelWriter(path, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "thresholds_to_test = np.arange(0.05, 0.50, 0.01)\n",
    "\n",
    "rows = []\n",
    "notes_common = f\"weight_step={WEIGHT_STEP} batch={BATCH_SIZE} n_samples={len(valid_indices)} decode_failures={decode_failures}\"\n",
    "\n",
    "def get_active_models_name(weights, names):\n",
    "    \"\"\"Genera nome modello con solo modelli attivi (peso > 0).\"\"\"\n",
    "    active = [(w, n) for w, n in zip(weights, names) if w > 0]\n",
    "    if len(active) == 3:\n",
    "        return 'LateFusion-3way: ' + '+'.join(names)\n",
    "    elif len(active) == 2:\n",
    "        return 'LateFusion-2way: ' + '+'.join(n for w, n in active)\n",
    "    else:\n",
    "        return f'Single: {active[0][1]}' if active else 'Unknown'\n",
    "\n",
    "def get_weights_description(weights, names):\n",
    "    \"\"\"Genera descrizione pesi con nomi modelli.\"\"\"\n",
    "    parts = [f\"{n}={w:.2f}\" for n, w in zip(names, weights) if w > 0]\n",
    "    return ', '.join(parts)\n",
    "\n",
    "for combo in weight_combos:\n",
    "    pers = np.array(acc[combo]['pers'], dtype=np.float32)\n",
    "    hs = human_valid\n",
    "\n",
    "    # Task A (High Quality)\n",
    "    hq_chars = max(1, int(acc[combo]['hq_chars']))\n",
    "    per_high = float(acc[combo]['hq_edits']) / float(hq_chars)  # 0..1\n",
    "    per_high_pct = per_high * 100.0\n",
    "    acc_high_pct = (1.0 - per_high) * 100.0\n",
    "\n",
    "    # Task B\n",
    "    try:\n",
    "        pearson_per, _ = pearsonr(1.0 - pers, hs)\n",
    "    except Exception:\n",
    "        pearson_per = float('nan')\n",
    "    try:\n",
    "        spearman_per, _ = spearmanr(1.0 - pers, hs)\n",
    "    except Exception:\n",
    "        spearman_per = float('nan')\n",
    "\n",
    "    # Task C\n",
    "    y_true = (hs <= 6.0).astype(int)\n",
    "    y_prob = pers\n",
    "\n",
    "    best_f1 = -1.0\n",
    "    best_threshold = float(thresholds_to_test[0])\n",
    "    for t in thresholds_to_test:\n",
    "        y_pred_t = (y_prob >= t).astype(int)\n",
    "        _, _, f1_t, _ = precision_recall_fscore_support(y_true, y_pred_t, average='binary', zero_division=0)\n",
    "        if f1_t > best_f1:\n",
    "            best_f1 = float(f1_t)\n",
    "            best_threshold = float(t)\n",
    "\n",
    "    y_pred = (y_prob >= best_threshold).astype(int)\n",
    "    try:\n",
    "        auc = float(roc_auc_score(y_true, y_prob))\n",
    "    except ValueError:\n",
    "        auc = 0.5\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "\n",
    "    # Genera nome modello specifico per questa combinazione\n",
    "    combo_model_name = get_active_models_name(combo, model_names)\n",
    "    # Genera note con descrizione pesi\n",
    "    weights_desc = get_weights_description(combo, model_names)\n",
    "    notes = f\"{weights_desc} | {notes_common}\"\n",
    "\n",
    "    row = {\n",
    "        'Model_Name': combo_model_name,\n",
    "        'Architecture': ARCHITECTURE,\n",
    "        'Training_Data': TRAINING_DATA,\n",
    "        'TaskA_PER_HighQuality': float(per_high_pct),\n",
    "        'TaskA_Accuracy': float(acc_high_pct),\n",
    "        'TaskB_Pearson_r': float(pearson_per),\n",
    "        'TaskB_Spearman_rho': float(spearman_per),\n",
    "        'TaskC_AUC_ROC': float(auc),\n",
    "        'TaskC_F1_Score': float(f1),\n",
    "        'TaskC_Recall_Errors': float(recall),\n",
    "        'TaskC_Precision': float(precision),\n",
    "        'TaskC_Threshold': float(best_threshold),\n",
    "        'Notes': notes,\n",
    "    }\n",
    "    rows.append(row)\n",
    "    append_row_track_benchmark_xlsx(OUTPUT_XLSX, row)\n",
    "\n",
    "print('‚úì wrote (track_benchmark schema):', OUTPUT_XLSX)\n",
    "df_out = pd.DataFrame(rows)\n",
    "df_out = df_out.sort_values(['TaskC_AUC_ROC', 'TaskC_F1_Score'], ascending=False)\n",
    "df_out.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be2cd5",
   "metadata": {},
   "source": [
    "## ‚úÖ Output\n",
    "\n",
    "- Excel (schema `track_benchmark.py`): `/kaggle/working/pronuncIAtion/benchmark_results.xlsx`\n",
    "- In Kaggle: apri il tab **Output** e scarica il file.\n",
    "- Ogni combinazione di pesi √® una riga; i pesi sono in `Notes`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
