{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß™ Late Fusion Evaluation - HuBERT + WavLM \"Dream Team\"\n",
                "\n",
                "Valuta l'ensemble Late Fusion combinando:\n",
                "- **HuBERT Large**: Best PER (8.84%)\n",
                "- **WavLM Weighted**: Best AUC (0.8523)\n",
                "\n",
                "**Formula**: `final_logits = Œ± √ó logits_HuBERT + (1-Œ±) √ó logits_WavLM`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, zipfile, glob, shutil\n",
                "\n",
                "def detect_environment():\n",
                "    if 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules:\n",
                "        return 'colab'\n",
                "    elif '/kaggle' in os.getcwd() or 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
                "        return 'kaggle'\n",
                "    return 'local'\n",
                "\n",
                "ENV = detect_environment()\n",
                "print(f'üñ•Ô∏è Ambiente: {ENV.upper()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# COLAB Setup\n",
                "if ENV == 'colab':\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    \n",
                "    PROJECT_DIR = '/content/DeepLearning-Phoneme'\n",
                "    MODELS_DIR = '/content/drive/MyDrive/phoneme_checkpoints'\n",
                "    ZIP_PATH = '/content/drive/MyDrive/DeepLearning-Phoneme.zip'\n",
                "    \n",
                "    if os.path.exists(ZIP_PATH):\n",
                "        with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n",
                "            z.extractall('/content')\n",
                "        print('‚úì Extracted')\n",
                "    else:\n",
                "        raise FileNotFoundError(ZIP_PATH)\n",
                "    \n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KAGGLE Setup\n",
                "if ENV == 'kaggle':\n",
                "    PROJECT_DIR = '/kaggle/working/pronuncIAtion'\n",
                "    MODELS_DIR = '/kaggle/input'  # Will be set after listing inputs\n",
                "    \n",
                "    if not os.path.exists(PROJECT_DIR):\n",
                "        import subprocess\n",
                "        subprocess.run(['git', 'clone', 'https://github.com/maurocarlu/pronuncIAtion.git', PROJECT_DIR])\n",
                "    \n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)\n",
                "    print(f'‚úì Kaggle ready: {PROJECT_DIR}')\n",
                "    \n",
                "    # List available model inputs\n",
                "    print('\\nüì¶ Available Kaggle inputs:')\n",
                "    for d in os.listdir('/kaggle/input'):\n",
                "        print(f'  - {d}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LOCAL Setup\n",
                "if ENV == 'local':\n",
                "    PROJECT_DIR = os.getcwd()\n",
                "    if 'notebooks' in PROJECT_DIR:\n",
                "        PROJECT_DIR = os.path.dirname(PROJECT_DIR)\n",
                "    MODELS_DIR = f'{PROJECT_DIR}/outputs'\n",
                "\n",
                "os.chdir(PROJECT_DIR)\n",
                "sys.path.insert(0, PROJECT_DIR)\n",
                "print(f'üìÅ Project: {PROJECT_DIR}')\n",
                "print(f'ü§ñ Models: {MODELS_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'transformers', 'datasets', 'evaluate', 'jiwer', 'soundfile', 'librosa', 'scikit-learn', 'scipy', 'safetensors'])\n",
                "import torch\n",
                "print(f'üî• PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')\n",
                "if torch.cuda.is_available():\n",
                "    print(f'üìä GPU: {torch.cuda.get_device_name(0)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚öôÔ∏è Configuration - Model Paths\n",
                "\n",
                "**IMPORTANTE**: Modifica i path sotto per puntare ai tuoi modelli trainati."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚ö†Ô∏è MODIFICA QUESTI PATH!\n",
                "CONFIG = {\n",
                "    # Path al modello HuBERT Large trainato\n",
                "    'hubert_path': f'{MODELS_DIR}/hubert_large/final_model_hubert',\n",
                "    \n",
                "    # Path al modello WavLM Weighted trainato\n",
                "    'wavlm_path': f'{MODELS_DIR}/final_model_weighted',\n",
                "    \n",
                "    # Pesi da testare (Œ± per HuBERT, 1-Œ± per WavLM)\n",
                "    'weights': [0.3, 0.5, 0.7],\n",
                "    \n",
                "    # Output report\n",
                "    'output_report': f'{PROJECT_DIR}/docs/fusion_benchmark_results.md',\n",
                "}\n",
                "\n",
                "print('üìã Configuration:')\n",
                "for k, v in CONFIG.items():\n",
                "    if 'path' in k:\n",
                "        status = '‚úì' if os.path.exists(v) else '‚úó NOT FOUND'\n",
                "        print(f'  {status} {k}: {v}')\n",
                "    else:\n",
                "        print(f'  ‚Ä¢ {k}: {v}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîç Check Available Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List available models in MODELS_DIR\n",
                "print(f'ü§ñ Available models in {MODELS_DIR}:')\n",
                "\n",
                "if os.path.exists(MODELS_DIR):\n",
                "    for item in sorted(os.listdir(MODELS_DIR)):\n",
                "        path = os.path.join(MODELS_DIR, item)\n",
                "        if os.path.isdir(path):\n",
                "            # Check for config.json (indicates a model)\n",
                "            has_config = os.path.exists(os.path.join(path, 'config.json'))\n",
                "            marker = '‚úì' if has_config else 'üìÇ'\n",
                "            print(f'  {marker} {item}')\n",
                "            \n",
                "            # Also check for final_model subdirs\n",
                "            for sub in os.listdir(path):\n",
                "                sub_path = os.path.join(path, sub)\n",
                "                if os.path.isdir(sub_path) and os.path.exists(os.path.join(sub_path, 'config.json')):\n",
                "                    print(f'      ‚úì {item}/{sub}')\n",
                "else:\n",
                "    print(f'‚ùå Directory non esiste: {MODELS_DIR}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß™ Late Fusion Evaluation\n",
                "\n",
                "Esegue benchmark su SpeechOcean762 con diversi pesi Œ±:\n",
                "- **TASK A**: ASR Robustness (PER su high quality)\n",
                "- **TASK B**: Scoring Correlation (Pearson/Spearman)\n",
                "- **TASK C**: Mispronunciation Detection (AUC-ROC)\n",
                "\n",
                "**Record da battere**: AUC = 0.8552"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üß™ RUN LATE FUSION BENCHMARK (Weight Sweep)\n",
                "import subprocess\n",
                "\n",
                "# Prepare weights argument\n",
                "weights_str = ' '.join(str(w) for w in CONFIG['weights'])\n",
                "\n",
                "cmd = [\n",
                "    sys.executable, 'scripts/evaluation/evaluate_hubert_fusion.py',\n",
                "    '--model-hubert', CONFIG['hubert_path'],\n",
                "    '--model-wavlm', CONFIG['wavlm_path'],\n",
                "    '--weights'\n",
                "] + [str(w) for w in CONFIG['weights']]\n",
                "\n",
                "print(f'üöÄ Esecuzione: {\" \".join(cmd[:5])}...')\n",
                "print(f'   Pesi: {CONFIG[\"weights\"]}')\n",
                "print('=' * 70)\n",
                "\n",
                "result = subprocess.run(cmd, capture_output=False)\n",
                "\n",
                "if result.returncode == 0:\n",
                "    print('\\n‚úÖ Benchmark completato!')\n",
                "else:\n",
                "    print(f'\\n‚ùå Errore codice {result.returncode}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Single Weight Evaluation\n",
                "\n",
                "Per testare un singolo peso specifico:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üéØ TEST SINGLE WEIGHT\n",
                "SINGLE_WEIGHT = 0.5  # ‚Üê Modifica questo valore\n",
                "\n",
                "import subprocess\n",
                "result = subprocess.run([\n",
                "    sys.executable, 'scripts/evaluation/evaluate_hubert_fusion.py',\n",
                "    '--model-hubert', CONFIG['hubert_path'],\n",
                "    '--model-wavlm', CONFIG['wavlm_path'],\n",
                "    '--weight', str(SINGLE_WEIGHT),\n",
                "], capture_output=False)\n",
                "\n",
                "print('‚úÖ Done!' if result.returncode == 0 else f'‚ùå Errore {result.returncode}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Qualitative Analysis\n",
                "\n",
                "Genera un report dei casi dove HuBERT e WavLM divergono."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üìä QUALITATIVE ERROR ANALYSIS\n",
                "import subprocess\n",
                "\n",
                "result = subprocess.run([\n",
                "    sys.executable, 'scripts/evaluation/analyze_model_gap.py',\n",
                "    '--model-hubert', CONFIG['hubert_path'],\n",
                "    '--model-wavlm', CONFIG['wavlm_path'],\n",
                "    '--output-report', CONFIG['output_report'],\n",
                "    '--max-examples', '300',\n",
                "], capture_output=False)\n",
                "\n",
                "if result.returncode == 0:\n",
                "    print(f'\\n‚úÖ Report salvato: {CONFIG[\"output_report\"]}')\n",
                "else:\n",
                "    print(f'\\n‚ùå Errore {result.returncode}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View generated report\n",
                "if os.path.exists(CONFIG['output_report']):\n",
                "    with open(CONFIG['output_report'], 'r', encoding='utf-8') as f:\n",
                "        content = f.read()\n",
                "    print(content[:3000])  # First 3000 chars\n",
                "    if len(content) > 3000:\n",
                "        print('\\n... [truncated]')\n",
                "else:\n",
                "    print('‚ùå Report non trovato')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üíæ Download Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download qualitative report\n",
                "if ENV == 'colab' and os.path.exists(CONFIG['output_report']):\n",
                "    from google.colab import files\n",
                "    files.download(CONFIG['output_report'])\n",
                "    print('‚úì Download avviato')\n",
                "elif ENV == 'kaggle' and os.path.exists(CONFIG['output_report']):\n",
                "    shutil.copy(CONFIG['output_report'], '/kaggle/working/')\n",
                "    print(f'‚úì Copiato in /kaggle/working/')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìà Manual Results Entry\n",
                "\n",
                "Usa questa cella per registrare manualmente i risultati se necessario."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Manual results tracking\n",
                "RESULTS = {\n",
                "    # Format: weight -> {per, pearson, auc}\n",
                "    0.3: {'per': None, 'pearson': None, 'auc': None},\n",
                "    0.5: {'per': None, 'pearson': None, 'auc': None},\n",
                "    0.7: {'per': None, 'pearson': None, 'auc': None},\n",
                "}\n",
                "\n",
                "# Display table\n",
                "print('üìä LATE FUSION RESULTS')\n",
                "print('=' * 50)\n",
                "print(f'{\"Weight\":^10} | {\"PER\":^10} | {\"Pearson\":^10} | {\"AUC-ROC\":^10}')\n",
                "print('-' * 50)\n",
                "for w, r in RESULTS.items():\n",
                "    per = f\"{r['per']:.2f}%\" if r['per'] else 'TBD'\n",
                "    pear = f\"{r['pearson']:.4f}\" if r['pearson'] else 'TBD'\n",
                "    auc = f\"{r['auc']:.4f}\" if r['auc'] else 'TBD'\n",
                "    print(f'{w:^10} | {per:^10} | {pear:^10} | {auc:^10}')\n",
                "print('=' * 50)\n",
                "print('\\nüèÜ Record AUC da battere: 0.8552')"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}