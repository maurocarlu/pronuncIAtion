{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ Ensemble Evaluation - Late Fusion WavLM + WAVLM_LARGE\n",
    "\n",
    "Questo notebook esegue la Late Fusion dei modelli WavLM Weighted e WAVLM_LARGE per valutazione su SpeechOcean762.\n",
    "\n",
    "## Prerequisiti\n",
    "- WavLM Weighted trainato\n",
    "- WAVLM_LARGE trainato\n",
    "- Modelli nella cartella `outputs/backup/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Monta Google Drive e verifica GPU\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Estrai progetto\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "ZIP_PATH = \"/content/drive/MyDrive/phonemeRef.zip\"\n",
    "EXTRACT_PATH = \"/content\"\n",
    "PROJECT_DIR = \"/content/DeepLearning-Phoneme\"\n",
    "\n",
    "if os.path.exists(ZIP_PATH):\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_PATH)\n",
    "    # Trova cartella estratta\n",
    "    extracted = [f for f in os.listdir('/content/') if os.path.isdir(f'/content/{f}') and 'Phoneme' in f]\n",
    "    if extracted:\n",
    "        PROJECT_DIR = f'/content/{extracted[0]}'\n",
    "    print(f\"‚úì Estratto in {PROJECT_DIR}\")\n",
    "else:\n",
    "    print(f\"‚ùå File non trovato: {ZIP_PATH}\")\n",
    "\n",
    "# Cambia directory al progetto\n",
    "os.chdir(PROJECT_DIR)\n",
    "print(f\"‚úì Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Installa dipendenze\n",
    "!pip install -q transformers datasets evaluate jiwer soundfile librosa\n",
    "!pip install -q scipy scikit-learn torchcodec\n",
    "print(\"‚úì Dipendenze installate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurazione Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Path ai modelli trainati (dentro phonemeRef.zip)\n",
    "import os\n",
    "\n",
    "# ============================================================\n",
    "# PATH AI MODELLI (dentro outputs/backup/)\n",
    "# ============================================================\n",
    "WAVLM_WEIGHT_MODEL_PATH = f\"{PROJECT_DIR}/outputs/backup/wavLM_large/final_model_aug_comb_weighted\"\n",
    "WAVLM_LARGE_MODEL_PATH = f\"{PROJECT_DIR}/outputs/backup/wavLM_large/final_model_aug_comb\"\n",
    "\n",
    "# Peso per la fusion (0.5 = media, >0.5 = pi√π peso a WavLM)\n",
    "FUSION_WEIGHT = 0.5\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìÅ Configurazione Ensemble:\")\n",
    "print(f\"   WavLM Weighted: {WAVLM_WEIGHT_MODEL_PATH}\")\n",
    "print(f\"   WavLM Large:    {WAVLM_LARGE_MODEL_PATH}\")\n",
    "print(f\"   Fusion Weight:  {FUSION_WEIGHT}\")\n",
    "\n",
    "# Verifica esistenza\n",
    "for name, path in [(\"WavLM\", WAVLM_WEIGHT_MODEL_PATH), (\"WAVLM_LARGE\", WAVLM_LARGE_MODEL_PATH)]:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"   ‚úì {name}: trovato\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {name}: NON TROVATO!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Esegui Late Fusion Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Esegui Late Fusion Evaluation\n",
    "import os\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üî¨ LATE FUSION BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"WavLM: {WAVLM_WEIGHT_MODEL_PATH}\")\n",
    "print(f\"WAVLM_LARGE: {WAVLM_LARGE_MODEL_PATH}\")\n",
    "print(f\"Weight: {FUSION_WEIGHT}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/evaluation/evaluate_fusion.py \\\n",
    "    --model-a \"{WAVLM_WEIGHT_MODEL_PATH}\" \\\n",
    "    --model-b \"{WAVLM_LARGE_MODEL_PATH}\" \\\n",
    "    --weight {FUSION_WEIGHT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Confronto Modelli Singoli vs Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Valutazione WavLM Weighted singolo\n",
    "import os\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üî¨ VALUTAZIONE WAVLM WEIGHTED (singolo)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/evaluation/evaluate_speechocean.py --model-path \"{WAVLM_WEIGHT_MODEL_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Valutazione WAVLM_LARGE singolo\n",
    "import os\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üî¨ VALUTAZIONE WAVLM_LARGE (singolo)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/evaluation/evaluate_speechocean.py --model-path \"{WAVLM_LARGE_MODEL_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sperimenta con diversi Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Test diversi valori di weight\n",
    "# weight = peso per modello A/WavLM (1-weight = peso per WAVLM_LARGE)\n",
    "import os\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "for weight in [0.3, 0.5, 0.7]:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"üî¨ FUSION con Weight = {weight}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    !python scripts/evaluation/evaluate_fusion.py \\\n",
    "        --model-a \"{WAVLM_WEIGHT_MODEL_PATH}\" \\\n",
    "        --model-b \"{WAVLM_LARGE_MODEL_PATH}\" \\\n",
    "        --weight {weight} \\\n",
    "        --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salva Risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Registra risultati nel benchmark tracker\n",
    "# NOTA: Modifica i valori con i risultati ottenuti dal tuo run\n",
    "import os\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "# Esempio di comando (decommentare e modificare):\n",
    "# !python scripts/evaluation/track_benchmark.py \\\n",
    "#     --model_name \"Ensemble WavLM+WAVLM_LARGE\" \\\n",
    "#     --architecture Ensemble \\\n",
    "#     --training_data \"Aug_Comb\" \\\n",
    "#     --per XX.XX \\\n",
    "#     --pearson 0.XXXX \\\n",
    "#     --auc 0.XXXX \\\n",
    "#     --recall 0.XXXX \\\n",
    "#     --notes \"Late Fusion weight=0.5\"\n",
    "\n",
    "print(\"üìä Modifica i valori sopra con i tuoi risultati e riesegui la cella\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
