{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb1df1a",
   "metadata": {},
   "source": [
    "# üß† L-MAC Evaluation (SpeechOcean762)\n",
    "\n",
    "Questo notebook calcola **AI/AD** e genera esempi ascoltabili per L-MAC.\n",
    "\n",
    "**Supporta ambienti:**\n",
    "- üñ•Ô∏è Local\n",
    "- ‚òÅÔ∏è Google Colab  \n",
    "- üìä Kaggle (Dataset + Modelli da input)\n",
    "\n",
    "**Dataset:** SpeechOcean762 (full)  \n",
    "**Backbone:** HuBERT Large o Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec84ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Fix audio decoding: monkey-patch prima di qualsiasi uso di datasets\n",
    "import soundfile as sf\n",
    "import io\n",
    "import datasets\n",
    "import datasets.features.audio as audio_module\n",
    "\n",
    "def decode_audio_with_soundfile(self, value, token_per_repo_id=None):\n",
    "    \"\"\"Fallback audio decoder usando soundfile.\"\"\"\n",
    "    if isinstance(value, dict):\n",
    "        if \"bytes\" in value:\n",
    "            audio_bytes = value[\"bytes\"]\n",
    "            audio, sr = sf.read(io.BytesIO(audio_bytes))\n",
    "            return {\"array\": audio, \"sampling_rate\": sr, \"path\": value.get(\"path\", \"\")}\n",
    "        elif \"path\" in value:\n",
    "            audio, sr = sf.read(value[\"path\"])\n",
    "            return {\"array\": audio, \"sampling_rate\": sr, \"path\": value[\"path\"]}\n",
    "    return value\n",
    "\n",
    "audio_module.Audio.decode_example = decode_audio_with_soundfile\n",
    "print(\"‚úì Audio decoder patched to use soundfile\")\n",
    "\n",
    "def detect_environment():\n",
    "    if 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules:\n",
    "        return 'colab'\n",
    "    elif '/kaggle' in os.getcwd() or 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
    "        return 'kaggle'\n",
    "    return 'local'\n",
    "\n",
    "ENV = detect_environment()\n",
    "print(f'üñ•Ô∏è Ambiente: {ENV.upper()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b346c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies + clone repo\n",
    "pkgs = [\n",
    "    'transformers>=4.38',\n",
    "    'datasets>=2.18',\n",
    "    'evaluate',\n",
    "    'jiwer',\n",
    "    'soundfile',\n",
    "    'librosa',\n",
    "    'safetensors',\n",
    "    'accelerate',\n",
    "    'tqdm',\n",
    "    'pyyaml',\n",
    "    'pandas',\n",
    "]\n",
    "\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', *pkgs], check=False)\n",
    "\n",
    "import torch\n",
    "print(f'üî• PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'üìä GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "\n",
    "# Clone repo\n",
    "IS_KAGGLE = Path('/kaggle').exists()\n",
    "SKIP_CLONE = str(os.environ.get('DL_PHONEME_SKIP_CLONE', '')).strip().lower() in ('1', 'true', 'yes')\n",
    "REPO_URL = 'https://github.com/maurocarlu/pronuncIAtion.git'\n",
    "PROJECT_DIR = Path('/kaggle/working/pronuncIAtion') if IS_KAGGLE else Path.cwd().parent.parent\n",
    "\n",
    "if IS_KAGGLE and (not SKIP_CLONE) and REPO_URL:\n",
    "    if not PROJECT_DIR.exists():\n",
    "        print('Cloning repo:', REPO_URL)\n",
    "        subprocess.run(['git', 'clone', REPO_URL, str(PROJECT_DIR)], check=False)\n",
    "    else:\n",
    "        print('Repo gi√† presente:', PROJECT_DIR)\n",
    "\n",
    "if PROJECT_DIR.exists():\n",
    "    os.chdir(PROJECT_DIR)\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "print('CWD:', os.getcwd())\n",
    "print('PROJECT_DIR:', PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Kaggle: Symlink dati e path modelli ======\n",
    "DATA_INPUT = Path('/kaggle/input/pronunciation-data/data')\n",
    "DATA_TARGET = Path(PROJECT_DIR) / 'data'\n",
    "\n",
    "# Symlink data\n",
    "if Path('/kaggle').exists() and DATA_INPUT.exists():\n",
    "    try:\n",
    "        if not DATA_TARGET.exists():\n",
    "            os.symlink(str(DATA_INPUT), str(DATA_TARGET))\n",
    "            print('‚úì data symlink creato')\n",
    "    except Exception as e:\n",
    "        print('‚ö†Ô∏è Symlink fallito:', e)\n",
    "\n",
    "# ====== Model paths ======\n",
    "# Kaggle: modelli da input dataset\n",
    "KAGGLE_MODELS_PATH = Path('/kaggle/input/late-fusion/LateFusion')\n",
    "LOCAL_MODELS_PATH = PROJECT_DIR / 'outputs' / 'backup'\n",
    "\n",
    "if KAGGLE_MODELS_PATH.exists():\n",
    "    MODELS_ROOT = KAGGLE_MODELS_PATH\n",
    "    print(f'‚úì Using Kaggle models: {MODELS_ROOT}')\n",
    "else:\n",
    "    MODELS_ROOT = LOCAL_MODELS_PATH\n",
    "    print(f'‚úì Using local models: {MODELS_ROOT}')\n",
    "\n",
    "# Find available models\n",
    "print('\\nModelli disponibili:')\n",
    "for p in sorted(MODELS_ROOT.glob('**/config.json'))[:10]:\n",
    "    print(f'  ‚úì {p.parent.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9cfe5",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "Configura:\n",
    "- `BACKBONE`: tipo di backbone (`hubert` o `early_fusion`)\n",
    "- `TARGET_PHONEME`: fonema IPA target per L-MAC\n",
    "- `MODEL_PATH`: path al modello fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "BACKBONE = \"hubert\"  # oppure \"early_fusion\"\n",
    "TARGET_PHONEME = \"…™\"  # esempio IPA\n",
    "\n",
    "# Auto-detect model path based on environment\n",
    "if (MODELS_ROOT / 'final_model_hubert').exists():\n",
    "    MODEL_PATH = str(MODELS_ROOT / 'final_model_hubert')\n",
    "elif (MODELS_ROOT / 'hubert_large' / 'final_model_hubert').exists():\n",
    "    MODEL_PATH = str(MODELS_ROOT / 'hubert_large' / 'final_model_hubert')\n",
    "else:\n",
    "    # Fallback: cerca il primo modello con config.json\n",
    "    candidates = list(MODELS_ROOT.glob('**/config.json'))\n",
    "    MODEL_PATH = str(candidates[0].parent) if candidates else \"\"\n",
    "\n",
    "print(f'BACKBONE: {BACKBONE}')\n",
    "print(f'MODEL_PATH: {MODEL_PATH}')\n",
    "print(f'TARGET_PHONEME: {TARGET_PHONEME}')\n",
    "\n",
    "# Auto-find decoder checkpoint (if already trained)\n",
    "decoder_root = PROJECT_DIR / \"outputs\" / \"lmac\" / BACKBONE / TARGET_PHONEME\n",
    "candidates = sorted(decoder_root.glob(\"decoder_*.pt\"))\n",
    "DECODER_CKPT = str(candidates[-1]) if candidates else \"\"\n",
    "print(f'DECODER_CKPT: {DECODER_CKPT or \"Not found (will train)\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592437a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import dal progetto (gi√† in sys.path)\n",
    "from scripts.analysis.lmac_core import (\n",
    "    LMACBackboneConfig,\n",
    "    LMACSpeechOceanDataset,\n",
    "    LMACWrapper,\n",
    "    collate_audio_batch,\n",
    "    compute_ai_ad,\n",
    "    generate_listenable_map,\n",
    ")\n",
    "\n",
    "print('‚úì L-MAC imports loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c799af6",
   "metadata": {},
   "source": [
    "## üéØ Train Decoder (se non presente)\n",
    "\n",
    "Se il decoder L-MAC non √® gi√† stato trainato per il fonema target, lo alleniamo qui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix audio decoding: usa soundfile invece di torchcodec\n",
    "import datasets\n",
    "datasets.config.TORCHCODEC_AVAILABLE = False\n",
    "\n",
    "# Se ancora non funziona, forza soundfile:\n",
    "import os\n",
    "os.environ[\"HF_DATASETS_AUDIO_DECODER\"] = \"soundfile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe033a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAIN (se decoder non presente) ===\n",
    "from types import SimpleNamespace\n",
    "from importlib import reload\n",
    "from scripts.analysis import train_lmac_decoder\n",
    "reload(train_lmac_decoder)  # Ricarica per avere le ultime modifiche\n",
    "\n",
    "if not DECODER_CKPT:\n",
    "    print('üèãÔ∏è Training L-MAC decoder...')\n",
    "    args = SimpleNamespace(\n",
    "        model_path=MODEL_PATH,\n",
    "        backbone=BACKBONE,\n",
    "        target_phoneme=TARGET_PHONEME,\n",
    "        layer_ids=\"6,12,18,24\",\n",
    "        epochs=10,\n",
    "        batch_size=2,\n",
    "        lr=2e-4,\n",
    "        lambda_out=1.0,\n",
    "        lambda_reg=1e-4,\n",
    "        max_samples=None,\n",
    "        log_interval=50,\n",
    "        output_dir=str(PROJECT_DIR / \"outputs\" / \"lmac\"),\n",
    "    )\n",
    "    train_lmac_decoder.train_lmac(args)\n",
    "    candidates = sorted(decoder_root.glob(\"decoder_*.pt\"))\n",
    "    DECODER_CKPT = str(candidates[-1]) if candidates else \"\"\n",
    "    print(f'‚úì Decoder trained: {DECODER_CKPT}')\n",
    "else:\n",
    "    print(f'‚úì Using existing decoder: {DECODER_CKPT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load decoder + backbone ===\n",
    "if not DECODER_CKPT:\n",
    "    raise FileNotFoundError(f\"Decoder checkpoint non trovato in {decoder_root}\")\n",
    "\n",
    "config = LMACBackboneConfig(\n",
    "    backbone_type=BACKBONE,\n",
    "    model_path=MODEL_PATH,\n",
    "    layer_ids=(6, 12, 18, 24),\n",
    ")\n",
    "wrapper = LMACWrapper(config=config, target_phoneme=TARGET_PHONEME)\n",
    "ckpt = torch.load(DECODER_CKPT, map_location=\"cpu\")\n",
    "wrapper.decoder.load_state_dict(ckpt[\"decoder_state\"])\n",
    "wrapper.eval()\n",
    "print('‚úì L-MAC Wrapper loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc99ab3",
   "metadata": {},
   "source": [
    "## üìä Evaluation: AI / AD Metrics\n",
    "\n",
    "Calcola le metriche **Attribution Intersection (AI)** e **Attribution Deletion (AD)** su SpeechOcean762."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AI / AD on SpeechOcean762 (test) ===\n",
    "print('üìä Computing AI/AD metrics on SpeechOcean762...')\n",
    "test_ds = LMACSpeechOceanDataset(split=\"test\", target_phoneme=TARGET_PHONEME, full=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=2, shuffle=False, collate_fn=collate_audio_batch)\n",
    "metrics = compute_ai_ad(wrapper, test_loader, max_batches=None)\n",
    "print('\\nüìà Results:')\n",
    "for k, v in metrics.items():\n",
    "    print(f'  {k}: {v:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a74b9",
   "metadata": {},
   "source": [
    "## üîä Listenable Maps\n",
    "\n",
    "Genera audio modificati per visualizzare/ascoltare le aree attribuite al fonema target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff28075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Esempio ascoltabile ===\n",
    "# Seleziona un audio dal dataset e genera la mappa ascoltabile\n",
    "sample = test_ds[0]\n",
    "audio_path = None\n",
    "if isinstance(sample.get(\"audio\"), dict) and sample[\"audio\"].get(\"path\"):\n",
    "    audio_path = sample[\"audio\"][\"path\"]\n",
    "\n",
    "# Fallback: salva temporaneamente l'audio se non esiste path\n",
    "if audio_path is None:\n",
    "    import soundfile as sf\n",
    "    tmp_path = Path(PROJECT_DIR) / \"outputs\" / \"lmac\" / \"tmp_audio.wav\"\n",
    "    tmp_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sf.write(tmp_path, sample[\"audio\"], 16000)\n",
    "    audio_path = str(tmp_path)\n",
    "\n",
    "out_dir = str(PROJECT_DIR / \"outputs\" / \"lmac\" / \"listenable_maps\")\n",
    "out = generate_listenable_map(wrapper, audio_path, out_dir=out_dir)\n",
    "print(f'\\nüîä Generated listenable map: {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2c62d8",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (Kaggle)\n",
    "\n",
    "Libera spazio disco rimuovendo cache HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3df369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup disk (Kaggle)\n",
    "import shutil\n",
    "if ENV == 'kaggle':\n",
    "    for f in ['/root/.cache/huggingface']:\n",
    "        if os.path.exists(f) and not os.path.islink(f):\n",
    "            shutil.rmtree(f)\n",
    "            print(f'üóëÔ∏è Cleaned: {f}')\n",
    "    # Check disk space\n",
    "    !df -h /kaggle/working"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
