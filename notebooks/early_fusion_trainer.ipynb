{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîÄ Early Fusion Trainer - HuBERT Large + WavLM Base\n",
                "\n",
                "**Architettura**: Concatena feature di HuBERT Large (1024D) e WavLM Base (768D) ‚Üí CTC Head\n",
                "\n",
                "**Requisiti**: GPU con ‚â•8GB VRAM (T4, RTX 3080+) con 4-bit quantization\n",
                "\n",
                "**Modelli**:\n",
                "- HuBERT Large: `facebook/hubert-large-ls960-ft` (o checkpoint custom)\n",
                "- WavLM Base: `microsoft/wavlm-base` (o checkpoint custom fine-tuned)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, zipfile, glob, re, shutil\n",
                "\n",
                "def detect_environment():\n",
                "    if 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules:\n",
                "        return 'colab'\n",
                "    elif '/kaggle' in os.getcwd() or 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
                "        return 'kaggle'\n",
                "    return 'local'\n",
                "\n",
                "ENV = detect_environment()\n",
                "print(f'üñ•Ô∏è Ambiente: {ENV.upper()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# COLAB Setup\n",
                "if ENV == 'colab':\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    \n",
                "    DRIVE_BACKUP = '/content/drive/MyDrive/phoneme_checkpoints'\n",
                "    PROJECT_DIR = '/content/DeepLearning-Phoneme'\n",
                "    ZIP_PATH = '/content/drive/MyDrive/DeepLearning-Phoneme.zip'\n",
                "    \n",
                "    if os.path.exists(ZIP_PATH):\n",
                "        with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n",
                "            z.extractall('/content')\n",
                "        print('‚úì Extracted')\n",
                "    else:\n",
                "        raise FileNotFoundError(ZIP_PATH)\n",
                "    \n",
                "    os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KAGGLE Setup\n",
                "if ENV == 'kaggle':\n",
                "    PROJECT_DIR = '/kaggle/working/pronuncIAtion'\n",
                "    DRIVE_BACKUP = '/kaggle/working/checkpoints'\n",
                "    \n",
                "    if not os.path.exists(PROJECT_DIR):\n",
                "        import subprocess\n",
                "        subprocess.run(['git', 'clone', 'https://github.com/maurocarlu/pronuncIAtion.git', PROJECT_DIR])\n",
                "    else:\n",
                "        # Pull latest changes\n",
                "        subprocess.run(['git', '-C', PROJECT_DIR, 'pull', 'origin', 'main'])\n",
                "    \n",
                "    DATA_INPUT = '/kaggle/input/pronunciation-data/data'\n",
                "    DATA_TARGET = f'{PROJECT_DIR}/data'\n",
                "    \n",
                "    if os.path.islink(DATA_TARGET):\n",
                "        print('‚úì Data symlink exists')\n",
                "    elif os.path.exists(DATA_TARGET):\n",
                "        shutil.rmtree(DATA_TARGET)\n",
                "        os.symlink(DATA_INPUT, DATA_TARGET)\n",
                "    elif os.path.exists(DATA_INPUT):\n",
                "        os.symlink(DATA_INPUT, DATA_TARGET)\n",
                "    \n",
                "    os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)\n",
                "    print(f'‚úì Kaggle ready: {PROJECT_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LOCAL Setup\n",
                "if ENV == 'local':\n",
                "    PROJECT_DIR = os.getcwd()\n",
                "    if 'notebooks' in PROJECT_DIR:\n",
                "        PROJECT_DIR = os.path.dirname(PROJECT_DIR)\n",
                "    DRIVE_BACKUP = f'{PROJECT_DIR}/outputs'\n",
                "\n",
                "os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "os.chdir(PROJECT_DIR)\n",
                "sys.path.insert(0, PROJECT_DIR)\n",
                "print(f'üìÅ Project: {PROJECT_DIR}')\n",
                "print(f'üíæ Checkpoints: {DRIVE_BACKUP}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies (including bitsandbytes for 4-bit quantization)\n",
                "import subprocess\n",
                "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', \n",
                "                'transformers', 'datasets', 'evaluate', 'jiwer', \n",
                "                'soundfile', 'librosa', 'safetensors', \n",
                "                'bitsandbytes', 'accelerate'])  # Added for 4-bit\n",
                "\n",
                "import torch\n",
                "print(f'üî• PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')\n",
                "if torch.cuda.is_available():\n",
                "    print(f'üìä GPU: {torch.cuda.get_device_name(0)}')\n",
                "    print(f'üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚öôÔ∏è Configuration\n",
                "\n",
                "**IMPORTANTE**: Modifica `wavlm_path` per puntare al tuo WavLM fine-tuned!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚ö†Ô∏è MODIFICA QUESTI PATH SE NECESSARIO\n",
                "WAVLM_PATH = None  # None = usa microsoft/wavlm-base, oppure 'outputs/wavLM/final_model_aug_comb'\n",
                "HUBERT_PATH = None  # None = usa facebook/hubert-large-ls960-ft\n",
                "\n",
                "CONFIG = {\n",
                "    'csv_path': f'{PROJECT_DIR}/data/processed/combined_augmented.csv',\n",
                "    'vocab_path': f'{PROJECT_DIR}/data/processed/vocab.json',\n",
                "    'audio_base': PROJECT_DIR,\n",
                "    'output_dir': f'{DRIVE_BACKUP}/early_fusion',\n",
                "    \n",
                "    # Custom model paths (set to None to use defaults)\n",
                "    'wavlm_path': WAVLM_PATH,\n",
                "    'hubert_path': HUBERT_PATH,\n",
                "    \n",
                "    # Training params - optimized for T4 (16GB) with 4-bit quantization\n",
                "    'epochs': 5,\n",
                "    'batch_size': 1,  # Small for memory\n",
                "    'gradient_accumulation': 16,  # Effective batch = 16\n",
                "    'learning_rate': 1e-4,\n",
                "}\n",
                "\n",
                "print('üìã Configuration:')\n",
                "for k,v in CONFIG.items():\n",
                "    if v is None:\n",
                "        print(f'  ‚óã {k}: (default)')\n",
                "    elif 'path' in k or 'dir' in k:\n",
                "        status = '‚úì' if os.path.exists(str(v)) else '‚úó'\n",
                "        print(f'  {status} {k}: {v}')\n",
                "    else:\n",
                "        print(f'  ‚Ä¢ {k}: {v}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ Training Early Fusion\n",
                "\n",
                "**Architecture**:\n",
                "```\n",
                "Audio ‚Üí HuBERT Large (frozen, 4-bit) ‚Üí 1024D ‚îÄ‚îê\n",
                "                                              ‚îú‚Üí concat ‚Üí CTC Head ‚Üí IPA\n",
                "Audio ‚Üí WavLM Base (frozen, 4-bit)  ‚Üí 768D ‚îÄ‚îÄ‚îò\n",
                "```\n",
                "\n",
                "**Memory con 4-bit quantization**:\n",
                "- HuBERT Large: ~1.5GB\n",
                "- WavLM Base: ~0.5GB\n",
                "- **Totale: ~6-8GB** (fattibile su T4!)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üîÄ EARLY FUSION TRAINING\n",
                "import subprocess\n",
                "\n",
                "cmd = [\n",
                "    sys.executable, 'scripts/training/train_early_fusion.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', CONFIG['output_dir'],\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', str(CONFIG['batch_size']),\n",
                "    '--gradient-accumulation', str(CONFIG['gradient_accumulation']),\n",
                "    '--learning-rate', str(CONFIG['learning_rate']),\n",
                "]\n",
                "\n",
                "# Add custom model paths if specified\n",
                "if CONFIG.get('wavlm_path'):\n",
                "    cmd.extend(['--wavlm-path', CONFIG['wavlm_path']])\n",
                "if CONFIG.get('hubert_path'):\n",
                "    cmd.extend(['--hubert-path', CONFIG['hubert_path']])\n",
                "\n",
                "print('üöÄ Running command:')\n",
                "print(' '.join(cmd))\n",
                "print()\n",
                "\n",
                "result = subprocess.run(cmd, capture_output=False)\n",
                "\n",
                "if result.returncode == 0:\n",
                "    print('\\n‚úÖ Training completato!')\n",
                "else:\n",
                "    print(f'\\n‚ùå Training fallito con codice {result.returncode}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîÑ Resume Training (optional)\n",
                "\n",
                "Se il training √® stato interrotto, esegui questa cella per riprendere dall'ultimo checkpoint."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üîÑ RESUME FROM CHECKPOINT\n",
                "import subprocess\n",
                "\n",
                "cmd = [\n",
                "    sys.executable, 'scripts/training/train_early_fusion.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', CONFIG['output_dir'],\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', str(CONFIG['batch_size']),\n",
                "    '--resume',  # Resume flag\n",
                "]\n",
                "\n",
                "if CONFIG.get('wavlm_path'):\n",
                "    cmd.extend(['--wavlm-path', CONFIG['wavlm_path']])\n",
                "if CONFIG.get('hubert_path'):\n",
                "    cmd.extend(['--hubert-path', CONFIG['hubert_path']])\n",
                "\n",
                "result = subprocess.run(cmd, capture_output=False)\n",
                "print('‚úÖ Resume completato!' if result.returncode == 0 else f'‚ùå Errore {result.returncode}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Check Training Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List checkpoints\n",
                "output_dir = CONFIG['output_dir']\n",
                "if os.path.exists(output_dir):\n",
                "    files = sorted(os.listdir(output_dir))\n",
                "    print(f'üìÅ {output_dir}:')\n",
                "    for f in files:\n",
                "        path = os.path.join(output_dir, f)\n",
                "        if os.path.isdir(path):\n",
                "            size = sum(os.path.getsize(os.path.join(path, x)) for x in os.listdir(path) if os.path.isfile(os.path.join(path, x)))\n",
                "            print(f'  üìÇ {f} ({size/1e6:.1f} MB)')\n",
                "        else:\n",
                "            print(f'  üìÑ {f}')\n",
                "else:\n",
                "    print(f'‚ùå Output dir non esiste: {output_dir}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üíæ Download/Backup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create ZIP of final model\n",
                "import datetime\n",
                "\n",
                "final_model = f\"{CONFIG['output_dir']}/final_model_early_fusion\"\n",
                "\n",
                "if os.path.exists(final_model):\n",
                "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
                "    zip_name = f'early_fusion_final_{timestamp}'\n",
                "    \n",
                "    if ENV == 'kaggle':\n",
                "        zip_path = f'/kaggle/working/{zip_name}'\n",
                "    else:\n",
                "        zip_path = f'/content/{zip_name}' if ENV == 'colab' else f'{DRIVE_BACKUP}/{zip_name}'\n",
                "    \n",
                "    print(f'üì¶ Creating ZIP: {zip_name}.zip')\n",
                "    shutil.make_archive(zip_path, 'zip', final_model)\n",
                "    print(f'‚úì Created: {zip_path}.zip')\n",
                "    \n",
                "    if ENV == 'colab':\n",
                "        from google.colab import files\n",
                "        files.download(f'{zip_path}.zip')\n",
                "else:\n",
                "    print(f'‚ùå Final model not found: {final_model}')\n",
                "    print('üí° Run training first or check for checkpoints')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cleanup disk (Kaggle)\n",
                "if ENV == 'kaggle':\n",
                "    for f in ['/root/.cache/huggingface']:\n",
                "        if os.path.exists(f) and not os.path.islink(f):\n",
                "            shutil.rmtree(f)\n",
                "            print(f'üóëÔ∏è {f}')"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}