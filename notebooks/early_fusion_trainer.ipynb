{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîÄ Early Fusion Trainer ‚Äî 3 modelli (3 combinazioni)\n",
                "\n",
                "Questo notebook (stile simile al late-fusion):\n",
                "- clona la repo da GitHub (per usare gli script/file ‚Äúcorretti‚Äù)\n",
                "- legge da Kaggle Input una cartella/zip con **3 modelli fine-tunati**\n",
                "- lancia il training Early Fusion per tutte le **3 coppie possibili**: (1,2), (1,3), (2,3)\n",
                "\n",
                "Nota: Early Fusion usa **2 backbone alla volta** ‚Üí per 3 modelli ci sono 3 run separate."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, zipfile, glob, re, shutil\n",
                "\n",
                "def detect_environment():\n",
                "    if 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules:\n",
                "        return 'colab'\n",
                "    elif '/kaggle' in os.getcwd() or 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
                "        return 'kaggle'\n",
                "    return 'local'\n",
                "\n",
                "ENV = detect_environment()\n",
                "print(f'üñ•Ô∏è Ambiente: {ENV.upper()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# (Legacy) Setup Colab/Kaggle/Local gestito nelle celle successive.\n",
                "# Questo notebook ora usa un setup stile late-fusion: install deps + clone repo in una singola cella.\n",
                "if ENV == 'colab':\n",
                "    print('Colab: usa la cella deps+clone e poi configura i path dei modelli/dati.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# (Legacy) Setup Kaggle gestito nelle celle successive.\n",
                "# Qui lasciamo solo un messaggio per evitare errori/indentation dal vecchio template.\n",
                "if ENV == 'kaggle':\n",
                "    print('Kaggle: usa la cella deps+clone e poi la cella di configurazione modelli (ZIP_DATASET_NAME / ZIP_FILENAME).')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# (Legacy) Setup local gestito nelle celle successive.\n",
                "if ENV == 'local':\n",
                "    print('Local: usa la cella deps+clone e poi setta LOCAL_EARLYFUSION_MODELS_ROOT se vuoi usare modelli locali.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install deps (Kaggle/Colab/Local) + clone repo (stile late-fusion)\n",
                "import os, sys, subprocess\n",
                "from pathlib import Path\n",
                "\n",
                "pkgs = [\n",
                "    'transformers>=4.38',\n",
                "    'datasets>=2.18',\n",
                "    'evaluate',\n",
                "    'jiwer',\n",
                "    'soundfile',\n",
                "    'librosa',\n",
                "    'safetensors',\n",
                "    'accelerate',\n",
                "    'tqdm',\n",
                "    'pyyaml',\n",
                "    'pandas',\n",
                "]\n",
                "\n",
                "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', *pkgs], check=False)\n",
                "\n",
                "import torch\n",
                "print(f'üî• PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')\n",
                "if torch.cuda.is_available():\n",
                "    print(f'üìä GPU: {torch.cuda.get_device_name(0)}')\n",
                "    print(f'üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
                "\n",
                "# ---- clone repo (default ON su Kaggle) ----\n",
                "IS_KAGGLE = Path('/kaggle').exists()\n",
                "SKIP_CLONE = str(os.environ.get('DL_PHONEME_SKIP_CLONE', '')).strip().lower() in ('1', 'true', 'yes')\n",
                "\n",
                "REPO_URL_DEFAULT = 'https://github.com/maurocarlu/pronuncIAtion.git'\n",
                "REPO_URL = str(os.environ.get('DL_PHONEME_REPO_URL', REPO_URL_DEFAULT)).strip()\n",
                "\n",
                "PROJECT_DIR = (Path('/kaggle/working/pronuncIAtion') if IS_KAGGLE else Path.cwd())\n",
                "\n",
                "if IS_KAGGLE and (not SKIP_CLONE) and REPO_URL:\n",
                "    if not PROJECT_DIR.exists():\n",
                "        print('Cloning repo:', REPO_URL)\n",
                "        subprocess.run(['git', 'clone', REPO_URL, str(PROJECT_DIR)], check=False)\n",
                "    else:\n",
                "        print('Repo gi√† presente:', PROJECT_DIR)\n",
                "else:\n",
                "    if IS_KAGGLE and SKIP_CLONE:\n",
                "        print('Repo clone skipped (DL_PHONEME_SKIP_CLONE=1).')\n",
                "    else:\n",
                "        print('Repo clone skipped (not running on Kaggle).')\n",
                "\n",
                "# Entra nella repo se esiste (cos√¨ i path coincidono con late-fusion)\n",
                "if PROJECT_DIR.exists():\n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, str(PROJECT_DIR))\n",
                "print('CWD:', os.getcwd())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚öôÔ∏è Configuration (simile al late-fusion)\n",
                "\n",
                "- Configura dove si trovano i **3 modelli** in Kaggle Input (cartella o zip).\n",
                "- Configura output e parametri training.\n",
                "- La cella successiva creer√† automaticamente le 3 run (coppie)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import zipfile\n",
                "import shutil\n",
                "import glob\n",
                "import os\n",
                "\n",
                "# ====== Kaggle input: 3 modelli (cartella o zip) ======\n",
                "# ‚úÖ tuoi path Kaggle\n",
                "KAGGLE_MODELS_PATH = Path('/kaggle/input/late-fusion/LateFusion')\n",
                "\n",
                "# Se vuoi usare la logica dataset+nome (come late-fusion notebook), puoi ancora farlo:\n",
                "KAGGLE_INPUT_DATASET_DIR = '/kaggle/input'\n",
                "ZIP_DATASET_NAME = os.environ.get('KAGGLE_EARLYFUSION_MODELS_DATASET', 'late-fusion')\n",
                "ZIP_FILENAME = os.environ.get('KAGGLE_EARLYFUSION_MODELS_NAME', 'LateFusion')  # directory o .zip\n",
                "ZIP_PATH = Path(KAGGLE_INPUT_DATASET_DIR) / ZIP_DATASET_NAME / ZIP_FILENAME\n",
                "\n",
                "# Priorit√†: usa direttamente il path completo se esiste\n",
                "MODELS_INPUT = KAGGLE_MODELS_PATH if KAGGLE_MODELS_PATH.exists() else ZIP_PATH\n",
                "\n",
                "EXTRACT_DIR = Path('/kaggle/working/early_fusion_models_extracted')\n",
                "EXTRACT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print('MODELS_INPUT:', MODELS_INPUT)\n",
                "print('Exists:', MODELS_INPUT.exists())\n",
                "\n",
                "if Path('/kaggle').exists():\n",
                "    assert MODELS_INPUT.exists(), (\n",
                "        f'Percorso modelli non trovato: {MODELS_INPUT}. '\n",
                "        'Controlla che il Kaggle Dataset input sia montato correttamente.'\n",
                "    )\n",
                "\n",
                "# Kaggle pu√≤ montare direttamente una CARTELLA invece di uno zip\n",
                "if MODELS_INPUT.exists() and MODELS_INPUT.is_dir():\n",
                "    MODELS_ROOT = MODELS_INPUT\n",
                "    print('‚ÑπÔ∏è MODELS_ROOT √® una directory (ok).')\n",
                "elif MODELS_INPUT.exists():\n",
                "    MODELS_ROOT = EXTRACT_DIR\n",
                "    with zipfile.ZipFile(MODELS_INPUT, 'r') as z:\n",
                "        z.extractall(EXTRACT_DIR)\n",
                "    print('‚úì Extracted to:', EXTRACT_DIR)\n",
                "else:\n",
                "    # Local fallback: prova a usare una cartella locale se non sei su Kaggle\n",
                "    MODELS_ROOT = Path(os.environ.get('LOCAL_EARLYFUSION_MODELS_ROOT', str(PROJECT_DIR / 'outputs' / 'backup')))\n",
                "    print('‚ÑπÔ∏è Using local MODELS_ROOT:', MODELS_ROOT)\n",
                "\n",
                "# Trova directory che contengono config.json (modelli HF)\n",
                "candidate_model_dirs = sorted({p.parent for p in Path(MODELS_ROOT).glob('**/config.json')})\n",
                "print(f'Found {len(candidate_model_dirs)} candidate model dirs')\n",
                "for p in candidate_model_dirs[:20]:\n",
                "    print('  ‚úì', p)\n",
                "if len(candidate_model_dirs) > 20:\n",
                "    print('  ...')\n",
                "\n",
                "# AUTO-select (se possibile) altrimenti imposta manualmente MODEL_DIRS\n",
                "MODEL_DIRS = None\n",
                "if len(candidate_model_dirs) == 3:\n",
                "    MODEL_DIRS = [str(p) for p in candidate_model_dirs]\n",
                "elif len(candidate_model_dirs) > 3:\n",
                "    # euristica: prendi le ultime 3 (spesso i final_model stanno pi√π in profondit√†)\n",
                "    MODEL_DIRS = [str(p) for p in candidate_model_dirs[-3:]]\n",
                "\n",
                "# Se vuoi forzare manualmente, decommenta e modifica:\n",
                "# MODEL_DIRS = [\n",
                "#   str(Path(MODELS_ROOT) / 'hubert_large' / 'final_model_hubert'),\n",
                "#   str(Path(MODELS_ROOT) / 'wavLM_large' / 'final_model_wavlm_large'),\n",
                "#   str(Path(MODELS_ROOT) / 'wav2vec2_phoneme' / 'final_model'),\n",
                "# ]\n",
                "\n",
                "assert MODEL_DIRS is not None and len(MODEL_DIRS) == 3, (\n",
                "    'Imposta MODEL_DIRS manualmente: nello zip/directory ci sono !=3 cartelle modello.'\n",
                " )\n",
                "\n",
                "print('\\n‚úÖ Selected MODEL_DIRS:')\n",
                "for i, p in enumerate(MODEL_DIRS, start=1):\n",
                "    p = Path(p)\n",
                "    print(f'  Model {i}: {p} | exists={p.exists()} | has_config={(p/\"config.json\").exists()}')\n",
                "    assert p.exists() and (p / 'config.json').exists()\n",
                "\n",
                "MODEL_NAMES = [Path(p).name for p in MODEL_DIRS]\n",
                "print('MODEL_NAMES:', MODEL_NAMES)\n",
                "\n",
                "# ====== dataset/data mount (repo) ======\n",
                "# ‚úÖ tuo path Kaggle per il dataset\n",
                "DATA_INPUT = Path('/kaggle/input/pronunciation-data/data')\n",
                "DATA_TARGET = Path(PROJECT_DIR) / 'data'\n",
                "\n",
                "if Path('/kaggle').exists():\n",
                "    if DATA_INPUT.exists():\n",
                "        try:\n",
                "            if DATA_TARGET.is_symlink():\n",
                "                print('‚úì data symlink gi√† presente:', DATA_TARGET)\n",
                "            else:\n",
                "                if DATA_TARGET.exists():\n",
                "                    shutil.rmtree(DATA_TARGET)\n",
                "                os.symlink(str(DATA_INPUT), str(DATA_TARGET))\n",
                "                print('‚úì data symlink creato:', DATA_TARGET, '->', DATA_INPUT)\n",
                "        except Exception as e:\n",
                "            print('‚ö†Ô∏è Symlink data non riuscito:', repr(e))\n",
                "            print('   Provo copia (pi√π lenta / pi√π spazio)...')\n",
                "            try:\n",
                "                if not DATA_TARGET.exists():\n",
                "                    shutil.copytree(DATA_INPUT, DATA_TARGET)\n",
                "                    print('‚úì data copiata in repo:', DATA_TARGET)\n",
                "            except Exception as e2:\n",
                "                print('‚ùå Copy fallback fallito:', repr(e2))\n",
                "    else:\n",
                "        print('‚ö†Ô∏è DATA_INPUT non esiste:', DATA_INPUT)\n",
                "        print('   Se non ti serve il dataset della repo, ignora questo warning.')\n",
                "\n",
                "# ====== training config ======\n",
                "DRIVE_BACKUP = '/kaggle/working/checkpoints' if Path('/kaggle').exists() else str(PROJECT_DIR / 'outputs')\n",
                "os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "\n",
                "CONFIG = {\n",
                "    'csv_path': f'{PROJECT_DIR}/data/processed/combined_augmented.csv',\n",
                "    'vocab_path': f'{PROJECT_DIR}/data/processed/vocab.json',\n",
                "    'audio_base': str(PROJECT_DIR),\n",
                "    'output_base': f'{DRIVE_BACKUP}/early_fusion_pairs',\n",
                "    'epochs': int(os.environ.get('EARLYFUSION_EPOCHS', '5')),\n",
                "    'batch_size': int(os.environ.get('EARLYFUSION_BATCH', '1')),\n",
                "    'gradient_accumulation': int(os.environ.get('EARLYFUSION_ACCUM', '16')),\n",
                "    'learning_rate': float(os.environ.get('EARLYFUSION_LR', '1e-4')),\n",
                "}\n",
                "\n",
                "print('\\nüìã Training CONFIG:')\n",
                "for k,v in CONFIG.items():\n",
                "    if 'path' in k or 'base' in k:\n",
                "        status = '‚úì' if os.path.exists(str(v)) else '‚úó'\n",
                "        print(f'  {status} {k}: {v}')\n",
                "    else:\n",
                "        print(f'  ‚Ä¢ {k}: {v}')\n",
                "\n",
                "# Le 3 coppie possibili tra 3 modelli\n",
                "MODEL_PAIRS = [(0,1), (0,2), (1,2)]\n",
                "print('\\nPairs to train:', [(a+1,b+1) for a,b in MODEL_PAIRS])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ Training Early Fusion (3 coppie)\n",
                "\n",
                "Per ogni run, il modello Early Fusion concatena le feature dei **2 backbone scelti** e allena una CTC head.\n",
                "\n",
                "Esegui in ordine:\n",
                "1) Setup (deps + clone repo)\n",
                "2) Config (selezione 3 modelli da Kaggle input)\n",
                "3) Le 3 celle di training: (1,2), (1,3), (2,3)\n",
                "\n",
                "Nota: se sei su Kaggle T4, inizia con `batch_size=1` e `gradient_accumulation=16`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üîÄ EARLY FUSION TRAINING ‚Äî coppia (1,2)\n",
                "import subprocess\n",
                "from pathlib import Path\n",
                "\n",
                "a, b = MODEL_PAIRS[0]  # (0,1)\n",
                "out_dir = Path(CONFIG['output_base']) / f\"pair_{a+1}_{b+1}\"\n",
                "out_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "cmd = [\n",
                "    sys.executable, 'scripts/training/train_early_fusion.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', str(out_dir),\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', str(CONFIG['batch_size']),\n",
                "    '--gradient-accumulation', str(CONFIG['gradient_accumulation']),\n",
                "    '--learning-rate', str(CONFIG['learning_rate']),\n",
                "    '--model-a-path', MODEL_DIRS[a],\n",
                "    '--model-b-path', MODEL_DIRS[b],\n",
                "    '--no-weighted-backbone-b',\n",
                " ]\n",
                "\n",
                "print('üöÄ Running:')\n",
                "print(' '.join(cmd))\n",
                "print()\n",
                "\n",
                "result = subprocess.run(cmd, capture_output=False)\n",
                "print('‚úÖ OK' if result.returncode == 0 else f'‚ùå Exit code {result.returncode}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üîÄ EARLY FUSION TRAINING ‚Äî coppia (1,3)\n",
                "import subprocess\n",
                "from pathlib import Path\n",
                "\n",
                "a, b = MODEL_PAIRS[1]  # (0,2)\n",
                "out_dir = Path(CONFIG['output_base']) / f\"pair_{a+1}_{b+1}\"\n",
                "out_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "cmd = [\n",
                "    sys.executable, 'scripts/training/train_early_fusion.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', str(out_dir),\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', str(CONFIG['batch_size']),\n",
                "    '--gradient-accumulation', str(CONFIG['gradient_accumulation']),\n",
                "    '--learning-rate', str(CONFIG['learning_rate']),\n",
                "    '--model-a-path', MODEL_DIRS[a],\n",
                "    '--model-b-path', MODEL_DIRS[b],\n",
                "    '--no-weighted-backbone-b',\n",
                " ]\n",
                "\n",
                "print('üöÄ Running:')\n",
                "print(' '.join(cmd))\n",
                "print()\n",
                "\n",
                "result = subprocess.run(cmd, capture_output=False)\n",
                "print('‚úÖ OK' if result.returncode == 0 else f'‚ùå Exit code {result.returncode}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üîÄ EARLY FUSION TRAINING ‚Äî coppia (2,3)\n",
                "import subprocess\n",
                "from pathlib import Path\n",
                "\n",
                "a, b = MODEL_PAIRS[2]  # (1,2)\n",
                "out_dir = Path(CONFIG['output_base']) / f\"pair_{a+1}_{b+1}\"\n",
                "out_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "cmd = [\n",
                "    sys.executable, 'scripts/training/train_early_fusion.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', str(out_dir),\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', str(CONFIG['batch_size']),\n",
                "    '--gradient-accumulation', str(CONFIG['gradient_accumulation']),\n",
                "    '--learning-rate', str(CONFIG['learning_rate']),\n",
                "    '--model-a-path', MODEL_DIRS[a],\n",
                "    '--model-b-path', MODEL_DIRS[b],\n",
                "    '--no-weighted-backbone-b',\n",
                " ]\n",
                "\n",
                "print('üöÄ Running:')\n",
                "print(' '.join(cmd))\n",
                "print()\n",
                "\n",
                "result = subprocess.run(cmd, capture_output=False)\n",
                "print('‚úÖ OK' if result.returncode == 0 else f'‚ùå Exit code {result.returncode}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîÑ Resume (optional)\n",
                "\n",
                "Ogni cella di training riparte automaticamente dall‚Äôultimo checkpoint presente dentro la relativa cartella `pair_X_Y` (lo script fa auto-resume se trova `checkpoint-*`).\n",
                "\n",
                "Se vuoi forzare un resume manuale, usa la cella sotto e scegli la coppia."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üîÑ RESUME (manuale) ‚Äî scegli quale coppia riprendere\n",
                "import subprocess\n",
                "from pathlib import Path\n",
                "\n",
                "# 0 -> (1,2), 1 -> (1,3), 2 -> (2,3)\n",
                "PAIR_INDEX = 0\n",
                "a, b = MODEL_PAIRS[PAIR_INDEX]\n",
                "out_dir = Path(CONFIG['output_base']) / f\"pair_{a+1}_{b+1}\"\n",
                "out_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "cmd = [\n",
                "    sys.executable, 'scripts/training/train_early_fusion.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', str(out_dir),\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', str(CONFIG['batch_size']),\n",
                "    '--gradient-accumulation', str(CONFIG['gradient_accumulation']),\n",
                "    '--learning-rate', str(CONFIG['learning_rate']),\n",
                "    '--model-a-path', MODEL_DIRS[a],\n",
                "    '--model-b-path', MODEL_DIRS[b],\n",
                "    '--no-weighted-backbone-b',\n",
                "    '--resume',\n",
                " ]\n",
                "\n",
                "print('üöÄ Running (resume):')\n",
                "print(' '.join(cmd))\n",
                "print()\n",
                "\n",
                "result = subprocess.run(cmd, capture_output=False)\n",
                "print('‚úÖ OK' if result.returncode == 0 else f'‚ùå Exit code {result.returncode}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Check Training Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List output directories (pair runs)\n",
                "from pathlib import Path\n",
                "output_base = Path(CONFIG['output_base'])\n",
                "print('üìÅ output_base:', output_base)\n",
                "\n",
                "if output_base.exists():\n",
                "    for d in sorted(output_base.glob('pair_*_*')):\n",
                "        ckpts = sorted(d.glob('checkpoint-*'))\n",
                "        final = d / 'final_model_early_fusion'\n",
                "        print('-', d.name, '| checkpoints:', len(ckpts), '| final_model:', final.exists())\n",
                "else:\n",
                "    print('‚ùå output_base non esiste (run training prima)')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üíæ Download/Backup (optional)\n",
                "\n",
                "Crea uno zip del `final_model_early_fusion` per una coppia (o per tutte)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create ZIP of final model (choose a pair)\n",
                "import datetime\n",
                "from pathlib import Path\n",
                "import shutil\n",
                "\n",
                "# Se vuoi zippare tutte le coppie, metti ZIP_ALL=True\n",
                "ZIP_ALL = False\n",
                "PAIR_INDEX = 0  # usato solo se ZIP_ALL=False\n",
                "\n",
                "output_base = Path(CONFIG['output_base'])\n",
                "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
                "\n",
                "targets = []\n",
                "if ZIP_ALL:\n",
                "    targets = sorted(output_base.glob('pair_*_*'))\n",
                "else:\n",
                "    a, b = MODEL_PAIRS[PAIR_INDEX]\n",
                "    targets = [output_base / f\"pair_{a+1}_{b+1}\"]\n",
                "\n",
                "for t in targets:\n",
                "    final_model = t / 'final_model_early_fusion'\n",
                "    if not final_model.exists():\n",
                "        print(f'‚ùå Final model not found: {final_model}')\n",
                "        continue\n",
                "    zip_name = f\"early_fusion_{t.name}_{timestamp}\"\n",
                "    if Path('/kaggle').exists():\n",
                "        zip_path = f'/kaggle/working/{zip_name}'\n",
                "    else:\n",
                "        zip_path = str(output_base / zip_name)\n",
                "    print(f'üì¶ Creating ZIP: {zip_name}.zip')\n",
                "    shutil.make_archive(zip_path, 'zip', str(final_model))\n",
                "    print(f'‚úì Created: {zip_path}.zip')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cleanup disk (Kaggle)\n",
                "if ENV == 'kaggle':\n",
                "    for f in ['/root/.cache/huggingface']:\n",
                "        if os.path.exists(f) and not os.path.islink(f):\n",
                "            shutil.rmtree(f)\n",
                "            print(f'üóëÔ∏è {f}')"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
