{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Unified Trainer - Phoneme Recognition Benchmark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, zipfile, glob, re, shutil\n",
                "\n",
                "def detect_environment():\n",
                "    if 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules:\n",
                "        return 'colab'\n",
                "    elif '/kaggle' in os.getcwd() or 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
                "        return 'kaggle'\n",
                "    return 'local'\n",
                "\n",
                "ENV = detect_environment()\n",
                "print(f'üñ•Ô∏è Ambiente: {ENV.upper()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# COLAB Setup\n",
                "if ENV == 'colab':\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    \n",
                "    DRIVE_BACKUP = '/content/drive/MyDrive/phoneme_checkpoints'\n",
                "    PROJECT_DIR = '/content/DeepLearning-Phoneme'\n",
                "    ZIP_PATH = '/content/drive/MyDrive/DeepLearning-Phoneme.zip'\n",
                "    \n",
                "    if os.path.exists(ZIP_PATH):\n",
                "        with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n",
                "            z.extractall('/content')\n",
                "        print('‚úì Extracted')\n",
                "    else:\n",
                "        raise FileNotFoundError(ZIP_PATH)\n",
                "    \n",
                "    os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KAGGLE Setup\n",
                "if ENV == 'kaggle':\n",
                "    PROJECT_DIR = '/kaggle/working/pronuncIAtion'\n",
                "    DRIVE_BACKUP = '/kaggle/working/checkpoints'\n",
                "    \n",
                "    if not os.path.exists(PROJECT_DIR):\n",
                "        import subprocess\n",
                "        subprocess.run(['git', 'clone', 'https://github.com/maurocarlu/pronuncIAtion.git', PROJECT_DIR])\n",
                "    \n",
                "    DATA_INPUT = '/kaggle/input/pronunciation-data/data'\n",
                "    DATA_TARGET = f'{PROJECT_DIR}/data'\n",
                "    \n",
                "    if os.path.islink(DATA_TARGET):\n",
                "        print('‚úì Data symlink exists')\n",
                "    elif os.path.exists(DATA_TARGET):\n",
                "        shutil.rmtree(DATA_TARGET)\n",
                "        os.symlink(DATA_INPUT, DATA_TARGET)\n",
                "    elif os.path.exists(DATA_INPUT):\n",
                "        os.symlink(DATA_INPUT, DATA_TARGET)\n",
                "    \n",
                "    os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)\n",
                "    print(f'‚úì Kaggle ready: {PROJECT_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LOCAL Setup\n",
                "if ENV == 'local':\n",
                "    PROJECT_DIR = os.getcwd()\n",
                "    if 'notebooks' in PROJECT_DIR:\n",
                "        PROJECT_DIR = os.path.dirname(PROJECT_DIR)\n",
                "    DRIVE_BACKUP = f'{PROJECT_DIR}/outputs'\n",
                "\n",
                "os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "os.chdir(PROJECT_DIR)\n",
                "sys.path.insert(0, PROJECT_DIR)\n",
                "print(f'üìÅ Project: {PROJECT_DIR}')\n",
                "print(f'üíæ Checkpoints: {DRIVE_BACKUP}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'transformers', 'datasets', 'evaluate', 'jiwer', 'soundfile', 'librosa', 'bitsandbytes'])\n",
                "import torch\n",
                "print(f'üî• PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIG = {\n",
                "    'csv_path': f'{PROJECT_DIR}/data/processed/combined_augmented.csv',\n",
                "    'vocab_path': f'{PROJECT_DIR}/data/processed/vocab.json',\n",
                "    'audio_base': PROJECT_DIR,\n",
                "    'epochs': 10,\n",
                "    'output_base': DRIVE_BACKUP,\n",
                "}\n",
                "\n",
                "for k,v in CONFIG.items():\n",
                "    if 'path' in k:\n",
                "        status = '‚úì' if os.path.exists(v) else '‚úó'\n",
                "        print(f'{status} {k}: {v}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training - Choose Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. WAV2VEC2-BERT 2.0 (Recommended - Stable)\n",
                "import subprocess\n",
                "subprocess.run([\n",
                "    sys.executable, 'scripts/training/train_w2v2_bert.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', f\"{CONFIG['output_base']}/w2v2_bert\",\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', '8'\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. MMS 1B (Massively Multilingual Speech)\n",
                "# Note: Requires 16GB VRAM or use --use-4bit for smaller GPUs\n",
                "import subprocess\n",
                "subprocess.run([\n",
                "    sys.executable, 'scripts/training/train_mms.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', f\"{CONFIG['output_base']}/mms\",\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', '8'\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. WHISPER ENCODER\n",
                "import subprocess\n",
                "subprocess.run([\n",
                "    sys.executable, 'scripts/training/train_whisper_encoder.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', f\"{CONFIG['output_base']}/whisper_encoder\",\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', '4'\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. QWEN2-AUDIO (Linear Probe - encoder frozen)\n",
                "import subprocess\n",
                "subprocess.run([\n",
                "    sys.executable, 'scripts/training/train_qwen_audio.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', f\"{CONFIG['output_base']}/qwen_audio\",\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', '2'\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. SPEECHTOKENIZER\n",
                "import subprocess\n",
                "subprocess.run([\n",
                "    sys.executable, 'scripts/training/train_speechtokenizer.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', f\"{CONFIG['output_base']}/speechtokenizer\",\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', '4'\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. WAV2VEC2 PHONEME (lv60-pmp - Domain Init)\n",
                "import subprocess\n",
                "subprocess.run([\n",
                "    sys.executable, 'scripts/training/train_wav2vec2_phoneme.py',\n",
                "    '--data-csv', CONFIG['csv_path'],\n",
                "    '--vocab-path', CONFIG['vocab_path'],\n",
                "    '--audio-base', CONFIG['audio_base'],\n",
                "    '--output-dir', f\"{CONFIG['output_base']}/wav2vec2_phoneme\",\n",
                "    '--epochs', str(CONFIG['epochs']),\n",
                "    '--batch-size', '4',\n",
                "    '--learning-rate', '3e-5',\n",
                "])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Utilities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cleanup disk (Kaggle)\n",
                "if ENV == 'kaggle':\n",
                "    for f in ['/kaggle/working/checkpoints', '/root/.cache/huggingface']:\n",
                "        if os.path.exists(f) and not os.path.islink(f):\n",
                "            shutil.rmtree(f)\n",
                "            print(f'üóëÔ∏è {f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download checkpoints as ZIP (Kaggle)\n",
                "if ENV == 'kaggle':\n",
                "    for model in ['w2v2_bert', 'mms', 'whisper_encoder', 'qwen_audio', 'speechtokenizer']:\n",
                "        p = f'{DRIVE_BACKUP}/{model}'\n",
                "        if os.path.exists(p):\n",
                "            shutil.make_archive(f'/kaggle/working/{model}_ckpt', 'zip', p)\n",
                "            print(f'‚úì {model}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üì• Download checkpoints via browser (Colab only)\n",
                "if ENV == 'colab':\n",
                "    from google.colab import files\n",
                "    import datetime\n",
                "    \n",
                "    models_to_download = ['w2v2_bert', 'mms', 'whisper_encoder', 'qwen_audio', 'speechtokenizer']\n",
                "    \n",
                "    for model in models_to_download:\n",
                "        model_dir = f'{DRIVE_BACKUP}/{model}'\n",
                "        final_model = f'{model_dir}/final_model'\n",
                "        \n",
                "        # Prefer final_model if exists, otherwise use latest checkpoint\n",
                "        if os.path.exists(final_model):\n",
                "            source_dir = final_model\n",
                "            zip_name = f'{model}_final'\n",
                "        elif os.path.exists(model_dir):\n",
                "            # Find latest checkpoint\n",
                "            checkpoints = sorted(glob.glob(f'{model_dir}/checkpoint-*'), \n",
                "                               key=lambda x: int(x.split('-')[-1]) if x.split('-')[-1].isdigit() else 0)\n",
                "            if checkpoints:\n",
                "                source_dir = checkpoints[-1]\n",
                "                zip_name = f'{model}_{os.path.basename(source_dir)}'\n",
                "            else:\n",
                "                continue\n",
                "        else:\n",
                "            continue\n",
                "        \n",
                "        # Create ZIP in /content (faster than Drive)\n",
                "        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
                "        zip_path = f'/content/{zip_name}_{timestamp}'\n",
                "        print(f'üì¶ Zipping {source_dir}...')\n",
                "        shutil.make_archive(zip_path, 'zip', source_dir)\n",
                "        zip_file = f'{zip_path}.zip'\n",
                "        size_mb = os.path.getsize(zip_file) / (1024*1024)\n",
                "        print(f'‚úì Created {zip_file} ({size_mb:.1f} MB)')\n",
                "        \n",
                "        # Trigger browser download\n",
                "        print('‚¨áÔ∏è Starting download...')\n",
                "        files.download(zip_file)\n",
                "        print(f'‚úì {model} download complete!')"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
