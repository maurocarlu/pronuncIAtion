{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Unified Trainer - Phoneme Recognition Benchmark\n",
                "\n",
                "## Models\n",
                "1. Baseline MLP (Linear Probe)\n",
                "2. HuBERT Large\n",
                "3. WavLM Weighted\n",
                "4. XLS-R\n",
                "5. **Wav2Vec2 Large**\n",
                "6. **Whisper Encoder**\n",
                "7. **SpeechTokenizer**\n",
                "8. **Qwen2-Audio**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Ambiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, zipfile\n",
                "\n",
                "def detect_environment():\n",
                "    if 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules:\n",
                "        return 'colab'\n",
                "    elif '/kaggle' in os.getcwd() or 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
                "        return 'kaggle'\n",
                "    return 'local'\n",
                "\n",
                "ENV = detect_environment()\n",
                "print(f'üñ•Ô∏è Ambiente: {ENV.upper()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# COLAB Setup - Mount Drive & Extract from ZIP (NO GITHUB!)\n",
                "if ENV == 'colab':\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    \n",
                "    DRIVE_BACKUP = '/content/drive/MyDrive/phoneme_checkpoints'\n",
                "    os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "    \n",
                "    PROJECT_DIR = '/content/DeepLearning-Phoneme'\n",
                "    \n",
                "    # Extract PROJECT from Drive ZIP (contains code + data)\n",
                "    ZIP_PATH = '/content/drive/MyDrive/DeepLearning-Phoneme.zip'\n",
                "    \n",
                "    if os.path.exists(ZIP_PATH):\n",
                "        print(f'üì¶ Extracting project from {ZIP_PATH}...')\n",
                "        with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n",
                "            z.extractall('/content')\n",
                "        print('‚úì Project extracted')\n",
                "    else:\n",
                "        print(f'‚ùå ERROR: ZIP non trovato: {ZIP_PATH}')\n",
                "        print('Carica DeepLearning-Phoneme.zip su Google Drive in MyDrive/')\n",
                "        raise FileNotFoundError(ZIP_PATH)\n",
                "    \n",
                "    # Change to project directory\n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)\n",
                "            \n",
                "    print('‚úì Colab ready')\n",
                "    print(f'üìÅ Working dir: {os.getcwd()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KAGGLE Setup - Use Kaggle Dataset (NO GITHUB!)\n",
                "if ENV == 'kaggle':\n",
                "    import shutil\n",
                "    \n",
                "    # Il dataset √® in /kaggle/input/deeplearning-phoneme/DeepLearning-Phoneme\n",
                "    INPUT_DIR = '/kaggle/input/deeplearning-phoneme/DeepLearning-Phoneme'\n",
                "    PROJECT_DIR = '/kaggle/working/DeepLearning-Phoneme'\n",
                "    DRIVE_BACKUP = '/kaggle/working/checkpoints'\n",
                "    \n",
                "    os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "    \n",
                "    # Copy from input to working (Kaggle input is read-only)\n",
                "    if os.path.exists(INPUT_DIR) and not os.path.exists(PROJECT_DIR):\n",
                "        print(f'üì¶ Copying project from {INPUT_DIR}...')\n",
                "        shutil.copytree(INPUT_DIR, PROJECT_DIR)\n",
                "        print('‚úì Project copied')\n",
                "    elif os.path.exists(PROJECT_DIR):\n",
                "        print('‚úì Project gi√† presente in working directory')\n",
                "    else:\n",
                "        print('‚ùå ERROR: Dataset non trovato!')\n",
                "        print(f'Path atteso: {INPUT_DIR}')\n",
                "        print('Aggiungi il dataset \"deeplearning-phoneme\" al notebook Kaggle')\n",
                "        raise FileNotFoundError(INPUT_DIR)\n",
                "    \n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)\n",
                "    \n",
                "    # Install dependencies\n",
                "    !pip install -q speechtokenizer bitsandbytes accelerate\n",
                "    \n",
                "    print(f'‚úì Kaggle ready')\n",
                "    print(f'üìÅ Project: {os.getcwd()}')\n",
                "    print(f'üíæ Checkpoints: {DRIVE_BACKUP}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LOCAL Setup\n",
                "if ENV == 'local':\n",
                "    PROJECT_DIR = os.getcwd()\n",
                "    if 'notebooks' in PROJECT_DIR:\n",
                "        PROJECT_DIR = os.path.dirname(PROJECT_DIR)\n",
                "    DRIVE_BACKUP = f'{PROJECT_DIR}/outputs'\n",
                "\n",
                "os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "if os.path.exists(PROJECT_DIR):\n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)\n",
                "\n",
                "print(f'üìÅ Project: {PROJECT_DIR}')\n",
                "print(f'üíæ Checkpoints: {DRIVE_BACKUP}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q transformers datasets evaluate jiwer soundfile librosa torchcodec\n",
                "import torch\n",
                "print(f'üî• PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIG = {\n",
                "    'csv_path': f'{PROJECT_DIR}/data/processed/combined_augmented.csv',\n",
                "    'vocab_path': f'{PROJECT_DIR}/data/processed/vocab.json',\n",
                "    'audio_base': PROJECT_DIR,\n",
                "    'epochs': 10,\n",
                "    'output_base': DRIVE_BACKUP,\n",
                "}\n",
                "for k,v in CONFIG.items():\n",
                "    if 'path' in k:\n",
                "        print(f\"{'‚úì' if os.path.exists(v) else '‚úó'} {k}: {v}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Training - Existing Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Baseline MLP\n",
                "!python scripts/training/train_baseline_mlp.py \\\n",
                "    --csv-path \"{CONFIG['csv_path']}\" \\\n",
                "    --vocab-path \"{CONFIG['vocab_path']}\" \\\n",
                "    --audio-base \"{CONFIG['audio_base']}\" \\\n",
                "    --output-dir \"{CONFIG['output_base']}/baseline_mlp\" \\\n",
                "    --epochs {CONFIG['epochs']}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# HuBERT Large\n",
                "!python scripts/training/train_hubert.py \\\n",
                "    --data-csv \"{CONFIG['csv_path']}\" \\\n",
                "    --vocab-path \"{CONFIG['vocab_path']}\" \\\n",
                "    --audio-base \"{CONFIG['audio_base']}\" \\\n",
                "    --output-dir \"{CONFIG['output_base']}/hubert_large\" \\\n",
                "    --epochs {CONFIG['epochs']}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Training - NEW SOTA Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. WAV2VEC2 LARGE\n",
                "!python scripts/training/train_wav2vec2.py \\\n",
                "    --data-csv \"{CONFIG['csv_path']}\" \\\n",
                "    --vocab-path \"{CONFIG['vocab_path']}\" \\\n",
                "    --audio-base \"{CONFIG['audio_base']}\" \\\n",
                "    --output-dir \"{CONFIG['output_base']}/wav2vec2\" \\\n",
                "    --epochs {CONFIG['epochs']} --batch-size 4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. WHISPER ENCODER\n",
                "!python scripts/training/train_whisper_encoder.py \\\n",
                "    --data-csv \"{CONFIG['csv_path']}\" \\\n",
                "    --vocab-path \"{CONFIG['vocab_path']}\" \\\n",
                "    --audio-base \"{CONFIG['audio_base']}\" \\\n",
                "    --output-dir \"{CONFIG['output_base']}/whisper_encoder\" \\\n",
                "    --epochs {CONFIG['epochs']} --batch-size 4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. SPEECHTOKENIZER (Discrete)\n",
                "!python scripts/training/train_speechtokenizer.py \\\n",
                "    --data-csv \"{CONFIG['csv_path']}\" \\\n",
                "    --vocab-path \"{CONFIG['vocab_path']}\" \\\n",
                "    --audio-base \"{CONFIG['audio_base']}\" \\\n",
                "    --output-dir \"{CONFIG['output_base']}/speechtokenizer\" \\\n",
                "    --epochs {CONFIG['epochs']} --batch-size 8"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. QWEN2-AUDIO (4-bit)\n",
                "!python scripts/training/train_qwen_audio.py \\\n",
                "    --data-csv \"{CONFIG['csv_path']}\" \\\n",
                "    --vocab-path \"{CONFIG['vocab_path']}\" \\\n",
                "    --audio-base \"{CONFIG['audio_base']}\" \\\n",
                "    --output-dir \"{CONFIG['output_base']}/qwen_audio\" \\\n",
                "    --epochs {CONFIG['epochs']} --batch-size 2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate (replace MODEL with: wav2vec2, whisper_encoder, speechtokenizer, qwen_audio)\n",
                "MODEL = 'wav2vec2'\n",
                "!python scripts/evaluation/evaluate_speechocean.py \\\n",
                "    --model-path \"{CONFIG['output_base']}/{MODEL}/final_model_{MODEL}\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Download Checkpoints (Kaggle only)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KAGGLE: I checkpoint sono in /kaggle/working/checkpoints\n",
                "# Puoi scaricarli dal pannello Output dopo il commit\n",
                "if ENV == 'kaggle':\n",
                "    import shutil\n",
                "    # Crea ZIP per download\n",
                "    for model in ['wav2vec2', 'whisper_encoder', 'speechtokenizer', 'qwen_audio']:\n",
                "        model_path = f'{DRIVE_BACKUP}/{model}'\n",
                "        if os.path.exists(model_path):\n",
                "            zip_path = f'/kaggle/working/{model}_checkpoint'\n",
                "            shutil.make_archive(zip_path, 'zip', model_path)\n",
                "            print(f'‚úì {model}: {zip_path}.zip')\n",
                "    print('\\nüì• Scarica gli ZIP dal pannello Output!')"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}