{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Unified Trainer - Phoneme Recognition Benchmark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, zipfile, glob, re, shutil\n",
                "\n",
                "def detect_environment():\n",
                "    if 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules:\n",
                "        return 'colab'\n",
                "    elif '/kaggle' in os.getcwd() or 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
                "        return 'kaggle'\n",
                "    return 'local'\n",
                "\n",
                "ENV = detect_environment()\n",
                "print(f'üñ•Ô∏è Ambiente: {ENV.upper()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# COLAB Setup\n",
                "if ENV == 'colab':\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    \n",
                "    DRIVE_BACKUP = '/content/drive/MyDrive/phoneme_checkpoints'\n",
                "    PROJECT_DIR = '/content/DeepLearning-Phoneme'\n",
                "    ZIP_PATH = '/content/drive/MyDrive/DeepLearning-Phoneme.zip'\n",
                "    \n",
                "    if os.path.exists(ZIP_PATH):\n",
                "        with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n",
                "            z.extractall('/content')\n",
                "        print('‚úì Extracted')\n",
                "    else:\n",
                "        raise FileNotFoundError(ZIP_PATH)\n",
                "    \n",
                "    os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KAGGLE Setup - GitHub (code) + Dataset (data)\n",
                "if ENV == 'kaggle':\n",
                "    PROJECT_DIR = '/kaggle/working/pronuncIAtion'\n",
                "    DRIVE_BACKUP = '/kaggle/working/checkpoints'\n",
                "    \n",
                "    # 1. Clone code from GitHub\n",
                "    if not os.path.exists(PROJECT_DIR):\n",
                "        print('üì¶ Cloning from GitHub...')\n",
                "        !git clone https://github.com/maurocarlu/pronuncIAtion.git $PROJECT_DIR\n",
                "    else:\n",
                "        !cd $PROJECT_DIR && git pull\n",
                "    \n",
                "    # 2. Link data from Kaggle Dataset (instead of copy - saves disk space)\n",
                "    DATA_INPUT = '/kaggle/input/pronunciation-data/data'\n",
                "    DATA_TARGET = f'{PROJECT_DIR}/data'\n",
                "    \n",
                "    # Remove existing empty data folder and create symlink\n",
                "    if os.path.islink(DATA_TARGET):\n",
                "        print('‚úì Data symlink exists')\n",
                "    elif os.path.exists(DATA_TARGET):\n",
                "        print('üóëÔ∏è Removing empty data folder...')\n",
                "        shutil.rmtree(DATA_TARGET)\n",
                "        os.symlink(DATA_INPUT, DATA_TARGET)\n",
                "        print(f'‚úì Created symlink: {DATA_TARGET} -> {DATA_INPUT}')\n",
                "    elif os.path.exists(DATA_INPUT):\n",
                "        os.symlink(DATA_INPUT, DATA_TARGET)\n",
                "        print(f'‚úì Created symlink: {DATA_TARGET} -> {DATA_INPUT}')\n",
                "    else:\n",
                "        print('‚ùå Dataset not found!')\n",
                "        print('Add \"pronunciation-data\" dataset to the notebook')\n",
                "        !ls -la /kaggle/input/\n",
                "    \n",
                "    # Verify audio files exist\n",
                "    test_audio = f'{DATA_TARGET}/augmented_focused/audio'\n",
                "    if os.path.exists(test_audio):\n",
                "        audio_count = len(os.listdir(test_audio))\n",
                "        print(f'‚úì Audio files found: {audio_count} in augmented_focused')\n",
                "    else:\n",
                "        print(f'‚ùå Audio folder not found: {test_audio}')\n",
                "    \n",
                "    os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "    os.chdir(PROJECT_DIR)\n",
                "    sys.path.insert(0, PROJECT_DIR)\n",
                "    \n",
                "    !pip install -q soundfile librosa\n",
                "    \n",
                "    print(f'\\n‚úì Kaggle ready')\n",
                "    print(f'üìÅ Project: {PROJECT_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LOCAL Setup\n",
                "if ENV == 'local':\n",
                "    PROJECT_DIR = os.getcwd()\n",
                "    if 'notebooks' in PROJECT_DIR:\n",
                "        PROJECT_DIR = os.path.dirname(PROJECT_DIR)\n",
                "    DRIVE_BACKUP = f'{PROJECT_DIR}/outputs'\n",
                "\n",
                "os.makedirs(DRIVE_BACKUP, exist_ok=True)\n",
                "os.chdir(PROJECT_DIR)\n",
                "sys.path.insert(0, PROJECT_DIR)\n",
                "\n",
                "print(f'üìÅ Project: {PROJECT_DIR}')\n",
                "print(f'üíæ Checkpoints: {DRIVE_BACKUP}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers datasets evaluate jiwer soundfile librosa\n",
                "import torch\n",
                "print(f'üî• PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIG = {\n",
                "    'csv_path': f'{PROJECT_DIR}/data/processed/combined_augmented.csv',\n",
                "    'vocab_path': f'{PROJECT_DIR}/data/processed/vocab.json',\n",
                "    'audio_base': PROJECT_DIR,\n",
                "    'epochs': 10,\n",
                "    'output_base': DRIVE_BACKUP,\n",
                "}\n",
                "\n",
                "# Verify paths\n",
                "for k,v in CONFIG.items():\n",
                "    if 'path' in k:\n",
                "        print(f\"{'‚úì' if os.path.exists(v) else '‚úó'} {k}: {v}\")\n",
                "\n",
                "# === DEBUG: VERIFY DATA LOADING ===\n",
                "print(\"\\nüîç DEBUG: Testing Data Loading & Audio...\")\n",
                "import pandas as pd\n",
                "import librosa\n",
                "import numpy as np\n",
                "\n",
                "try:\n",
                "    # 1. Check CSV\n",
                "    df = pd.read_csv(CONFIG['csv_path'])\n",
                "    print(f\"   CSV Samples: {len(df)}\")\n",
                "    print(f\"   Columns: {list(df.columns)}\")\n",
                "    \n",
                "    # 2. Check Audio Loading for 3 random samples\n",
                "    samples = df.sample(3)\n",
                "    for idx, row in samples.iterrows():\n",
                "        path = row['audio_path']\n",
                "        # Handle windows backslashes in path just in case\n",
                "        clean_path = path.replace('\\\\', '/')\n",
                "        full_path = f\"{CONFIG['audio_base']}/{clean_path}\"\n",
                "        \n",
                "        print(f\"\\n   Testing sample {idx}: {full_path}\")\n",
                "        if os.path.exists(full_path):\n",
                "            y, sr = librosa.load(full_path, sr=16000)\n",
                "            duration = len(y)/sr\n",
                "            is_silent = np.allclose(y, 0, atol=1e-3)\n",
                "            print(f\"   ‚úì Loaded: {duration:.2f}s | SR: {sr}\")\n",
                "            print(f\"   ‚úì Silent: {is_silent} | Range: [{y.min():.3f}, {y.max():.3f}]\")\n",
                "            print(f\"   IPA: /{row['ipa_clean']}/\")\n",
                "        else:\n",
                "            print(f\"   ‚ùå File NOT found!\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå DATA DEBUG FAILED: {e}\")\n",
                "print(\"\\n\" + \"=\"*40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# WAV2VEC2\n",
                "!python scripts/training/train_wav2vec2.py \\\n",
                "    --data-csv \"{CONFIG['csv_path']}\" \\\n",
                "    --vocab-path \"{CONFIG['vocab_path']}\" \\\n",
                "    --audio-base \"{CONFIG['audio_base']}\" \\\n",
                "    --output-dir \"{CONFIG['output_base']}/wav2vec2\" \\\n",
                "    --epochs {CONFIG['epochs']} \\\n",
                "    --learning-rate 3e-4 \\\n",
                "    --batch-size 4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# WHISPER ENCODER\n",
                "!python scripts/training/train_whisper_encoder.py \\\n",
                "    --data-csv \"{CONFIG['csv_path']}\" \\\n",
                "    --vocab-path \"{CONFIG['vocab_path']}\" \\\n",
                "    --audio-base \"{CONFIG['audio_base']}\" \\\n",
                "    --output-dir \"{CONFIG['output_base']}/whisper_encoder\" \\\n",
                "    --epochs {CONFIG['epochs']} --batch-size 4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# QWEN2-AUDIO\n",
                "!python scripts/training/train_qwen_audio.py \\\n",
                "    --data-csv \"{CONFIG['csv_path']}\" \\\n",
                "    --vocab-path \"{CONFIG['vocab_path']}\" \\\n",
                "    --audio-base \"{CONFIG['audio_base']}\" \\\n",
                "    --output-dir \"{CONFIG['output_base']}/qwen_audio\" \\\n",
                "    --epochs {CONFIG['epochs']} --batch-size 2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Utilities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cleanup disk\n",
                "if ENV == 'kaggle':\n",
                "    for f in ['/kaggle/working/checkpoints', '/root/.cache/huggingface']:\n",
                "        if os.path.exists(f) and not os.path.islink(f):\n",
                "            shutil.rmtree(f)\n",
                "            print(f'üóëÔ∏è {f}')\n",
                "    !df -h /kaggle/working"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download checkpoints\n",
                "if ENV == 'kaggle':\n",
                "    for model in ['wav2vec2', 'whisper_encoder', 'qwen_audio']:\n",
                "        p = f'{DRIVE_BACKUP}/{model}'\n",
                "        if os.path.exists(p):\n",
                "            shutil.make_archive(f'/kaggle/working/{model}_ckpt', 'zip', p)\n",
                "            print(f'‚úì {model}')"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}