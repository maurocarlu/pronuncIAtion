# ðŸŽ™ï¸ DeepLearning-Phoneme

**Riconoscimento fonetico IPA da audio con architettura Ensemble (WavLM + XLS-R)**

Sistema di Automatic Phoneme Recognition (APR) e Pronunciation Scoring per speaker non-nativi, basato su ensemble di modelli WavLM e XLS-R con Late Fusion.

---

## ðŸ“š Documentazione

La documentazione completa del progetto Ã¨ disponibile nella cartella [`docs/`](docs/):

- **[ðŸ¦ Model Zoo](docs/MODEL_ZOO.md)**: Dettagli su tutti i modelli implementati (WavLM, HuBERT, Whisper, SpeechTokenizer, Qwen2-Audio, MMS).
- **[ðŸ—ï¸ Architecture Details](docs/ARCHITECTURE_DETAILS.md)**: Approfondimenti tecnici su Weighted Layer Sum, Ensemble e Custom CTC Heads.
- **[ðŸ§ª Benchmark Guide](docs/BENCHMARK_GUIDE.md)**: Metriche, Dataset (SpeechOcean762) e protocolli di valutazione.
- **[ðŸ““ Experiments Log](EXPERIMENTS.md)**: Diario cronologico degli esperimenti e risultati.
- **[ðŸ“š References](docs/REFERENCES.md)**: Bibliografia e paper citati.

---

## âœ¨ Features

- **Riconoscimento fonemi IPA** da audio inglese
- **Ensemble SOTA** con WavLM + XLS-R e Late Fusion
- **Weighted Layer Sum** per combinazione ottimale dei layer
- **Benchmark scientifico** su SpeechOcean762 (speaker non-nativi)
- **Supporto multi-ambiente**: Locale, Google Colab, Kaggle

---

## ðŸ¤– Modelli Implementati

| Modello | Params | Mode | VRAM | Script |
|---------|--------|------|------|--------|
| WavLM Large | 317M | Fine-tuning | ~12GB | `train_wavlm.py` |
| HuBERT Large | 317M | Fine-tuning | ~12GB | `train_hubert.py` |
| XLS-R 300M | 300M | Fine-tuning | ~10GB | `train_xlsr.py` |
| Whisper (Encoder) | 244M | Last 4 layers | ~8GB | `train_whisper_encoder.py` |
| SpeechTokenizer | 256K | 2-Stage | ~4GB | `train_speechtokenizer.py` |
| **Qwen2-Audio** | **260K** | **Linear Probe** | **~5GB** | `train_qwen_audio.py` |
| **Wav2Vec2-BERT** | **600M** | **Fine-tuning** | **~12GB** | `train_w2v2_bert.py` |
| **MMS 1B** | **1B** | **Fine-tuning** | **~16GB** | `train_mms.py` |
| Baseline MLP | 2M | Linear Probe | ~4GB | `train_baseline_mlp.py` |

> Dettagli completi: [docs/MODEL_ZOO.md](docs/MODEL_ZOO.md)

## Quick Start

### Installazione

```bash
git clone https://github.com/maurocarlu/DeepLearning-Phoneme.git
cd DeepLearning-Phoneme
pip install -r requirements.txt
```

### Valutazione Modelli

```bash
# Valutazione modelli standard (WavLM, HuBERT, XLS-R)
python scripts/evaluation/evaluate_speechocean.py --model-path outputs/final_model

# Valutazione SpeechTokenizer (Discrete)
python scripts/evaluation/evaluate_speechtokenizer.py --model-path outputs/speechtokenizer
```

### Training

Vedi il notebook unificato per addestrare qualsiasi modello:
[**`notebooks/unified_trainer.ipynb`**](notebooks/unified_trainer.ipynb)

## Struttura Progetto

```
DeepLearning-Phoneme/
â”œâ”€â”€ docs/                       # ðŸ“˜ DOCUMENTAZIONE COMPLETA
â”‚   â”œâ”€â”€ MODEL_ZOO.md            # Dettagli modelli
â”‚   â”œâ”€â”€ ARCHITECTURE_DETAILS.md # Dettagli tecnici
â”‚   â””â”€â”€ BENCHMARK_GUIDE.md      # Guida valutazione
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”œâ”€â”€ scripts/                    # Script Python
â”‚   â”œâ”€â”€ training/               # Script di training
â”‚   â”œâ”€â”€ evaluation/             # Script di valutazione
â”‚   â””â”€â”€ data/                   # Processing dati
â”œâ”€â”€ src/                        # Moduli sorgente
â””â”€â”€ EXPERIMENTS.md              # Log risultati
```

## Autori

Progetto universitario - Deep Learning, Magistrale Anno 2
