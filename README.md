# ðŸŽ™ï¸ DeepLearning-Phoneme

**Riconoscimento fonetico IPA da audio con architettura Ensemble (WavLM + XLS-R)**

Sistema di Automatic Phoneme Recognition (APR) e Pronunciation Scoring per speaker non-nativi, basato su ensemble di modelli WavLM e XLS-R con Late Fusion.

---

## ðŸ“š Documentazione

La documentazione completa del progetto Ã¨ disponibile nella cartella [`docs/`](docs/):

- **[ðŸ¦ Model Zoo](docs/MODEL_ZOO.md)**: Dettagli su tutti i modelli implementati (WavLM, HuBERT, Whisper, SpeechTokenizer, Qwen2-Audio, MMS).
- **[ðŸ—ï¸ Architecture Details](docs/ARCHITECTURE_DETAILS.md)**: Approfondimenti tecnici su Weighted Layer Sum, Ensemble e Custom CTC Heads.
- **[ðŸ§ª Benchmark Guide](docs/BENCHMARK_GUIDE.md)**: Metriche, Dataset (SpeechOcean762) e protocolli di valutazione.
- **[ðŸ““ Experiments Log](EXPERIMENTS.md)**: Diario cronologico degli esperimenti e risultati.
- **[ðŸ“š References](docs/REFERENCES.md)**: Bibliografia e paper citati.

---

## âœ¨ Features

- **Riconoscimento fonemi IPA** da audio inglese
- **Ensemble SOTA** con WavLM + XLS-R e Late Fusion
- **Weighted Layer Sum** per combinazione ottimale dei layer
- **Benchmark scientifico** su SpeechOcean762 (speaker non-nativi)
- **Supporto multi-ambiente**: Locale, Google Colab, Kaggle

---

## ðŸ¤– Modelli Implementati

| Modello | Params | Mode | VRAM | Status | Script |
|---------|--------|------|------|--------|--------|
| **HuBERT Large** | 317M | Fine-tuning | ~12GB | ðŸ† **Best PER: 8.84%** | `train_hubert.py` |
| **WavLM Weighted** | 317M | Fine-tuning | ~12GB | ðŸ† **Best AUC: 0.8523** | `train_weighted.py` |
| **Late Fusion** | 634M | Inference | ~16GB | ðŸ†• NEW | `evaluate_hubert_fusion.py` |
| **Early Fusion** | 634M | Frozen+CTC | ~20GB | ðŸ†• NEW | `train_early_fusion.py` |
| WavLM Large | 317M | Fine-tuning | ~12GB | âœ… | `train_wavlm.py` |
| XLS-R 300M | 300M | Fine-tuning | ~10GB | âœ… | `train_xlsr.py` |
| Whisper (Encoder) | 244M | Last 4 layers | ~8GB | âŒ | `train_whisper_encoder.py` |
| Baseline MLP | 2M | Linear Probe | ~4GB | âœ… | `train_baseline_mlp.py` |

> Dettagli completi: [docs/MODEL_ZOO.md](docs/MODEL_ZOO.md)

## Quick Start

### Installazione

```bash
git clone https://github.com/maurocarlu/DeepLearning-Phoneme.git
cd DeepLearning-Phoneme
pip install -r requirements.txt
```

### Valutazione Modelli

```bash
# Valutazione modelli standard (WavLM, HuBERT, XLS-R)
python scripts/evaluation/evaluate_speechocean.py --model-path outputs/final_model

# Valutazione SpeechTokenizer (Discrete)
python scripts/evaluation/evaluate_speechtokenizer.py --model-path outputs/speechtokenizer
```

### Training

Vedi il notebook unificato per addestrare qualsiasi modello:
[**`notebooks/unified_trainer.ipynb`**](notebooks/unified_trainer.ipynb)

## Struttura Progetto

```
DeepLearning-Phoneme/
â”œâ”€â”€ docs/                       # ðŸ“˜ DOCUMENTAZIONE COMPLETA
â”‚   â”œâ”€â”€ MODEL_ZOO.md            # Dettagli modelli
â”‚   â”œâ”€â”€ ARCHITECTURE_DETAILS.md # Dettagli tecnici
â”‚   â””â”€â”€ BENCHMARK_GUIDE.md      # Guida valutazione
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”œâ”€â”€ scripts/                    # Script Python
â”‚   â”œâ”€â”€ training/               # Script di training
â”‚   â”œâ”€â”€ evaluation/             # Script di valutazione
â”‚   â””â”€â”€ data/                   # Processing dati
â”œâ”€â”€ src/                        # Moduli sorgente
â””â”€â”€ EXPERIMENTS.md              # Log risultati
```

## Autori

Progetto universitario - Deep Learning, Magistrale Anno 2
