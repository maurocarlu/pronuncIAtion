{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üåç XLS-R Training (Modello Multilingua)\n",
                "\n",
                "Questo notebook addestra **XLS-R** (wav2vec2-xls-r-300m), un modello multilingua pre-addestrato su 128 lingue.\n",
                "\n",
                "**Perch√© XLS-R?**\n",
                "- Pre-training su 128 lingue ‚Üí variet√† fonetica maggiore\n",
                "- Complementa WavLM (focalizzato su inglese)\n",
                "- Ottimo per speaker non-nativi\n",
                "\n",
                "**‚ö†Ô∏è IMPORTANTE:**\n",
                "- XLS-R √® un modello grande (300M parametri)\n",
                "- Richiede ~12GB VRAM (usa T4 o migliore)\n",
                "- Training pi√π lento di WavLM (~2x)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Ambiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.1 Verifica GPU\n",
                "!nvidia-smi\n",
                "\n",
                "import torch\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA disponibile: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    gpu_name = torch.cuda.get_device_name(0)\n",
                "    vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
                "    print(f\"GPU: {gpu_name}\")\n",
                "    print(f\"VRAM: {vram:.1f} GB\")\n",
                "    \n",
                "    if vram < 12:\n",
                "        print(\"\\n‚ö†Ô∏è ATTENZIONE: XLS-R richiede ~12GB VRAM\")\n",
                "        print(\"   Potrebbe essere necessario ridurre batch_size\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.2 Monta Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "print(\"‚úÖ Drive montato\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.3 Estrai progetto da zip\n",
                "import os\n",
                "import zipfile\n",
                "from pathlib import Path\n",
                "\n",
                "ZIP_PATH = '/content/drive/MyDrive/phonemeRef.zip'\n",
                "EXTRACT_PATH = '/content/DeepLearning-Phoneme'\n",
                "\n",
                "if not os.path.exists(ZIP_PATH):\n",
                "    raise FileNotFoundError(f\"‚ùå File non trovato: {ZIP_PATH}\\nCarica phonemeRef.zip su Google Drive\")\n",
                "\n",
                "print(f\"üì¶ Estrazione {ZIP_PATH}...\")\n",
                "with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
                "    zip_ref.extractall('/content/')\n",
                "\n",
                "# Trova cartella estratta\n",
                "extracted = [f for f in os.listdir('/content/') if os.path.isdir(f'/content/{f}') and 'Phoneme' in f]\n",
                "if extracted:\n",
                "    EXTRACT_PATH = f'/content/{extracted[0]}'\n",
                "\n",
                "os.chdir(EXTRACT_PATH)\n",
                "print(f\"‚úÖ Progetto in: {EXTRACT_PATH}\")\n",
                "!ls -la"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.4 Installa dipendenze\n",
                "!pip install -q transformers datasets evaluate jiwer accelerate soundfile librosa pyyaml tqdm\n",
                "print(\"\\n‚úÖ Dipendenze installate\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preparazione Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.1 Carica dataset\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "\n",
                "# Opzioni dataset (DEVE essere lo stesso di WavLM!)\n",
                "DATASET_OPTIONS = [\n",
                "    'data/processed/combined_augmented.csv',\n",
                "    'data/processed/combined_dataset.csv',\n",
                "    'data/processed/phonemeref_processed.csv',\n",
                "]\n",
                "\n",
                "DATASET_CSV = None\n",
                "for opt in DATASET_OPTIONS:\n",
                "    if Path(opt).exists():\n",
                "        DATASET_CSV = opt\n",
                "        break\n",
                "\n",
                "if not DATASET_CSV:\n",
                "    raise FileNotFoundError(\"‚ùå Nessun dataset trovato!\")\n",
                "\n",
                "df = pd.read_csv(DATASET_CSV)\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"   Samples: {len(df):,}\")\n",
                "print(f\"\\n‚ö†Ô∏è IMPORTANTE: Usa lo stesso dataset di WavLM per l'ensemble!\")\n",
                "\n",
                "if 'source' in df.columns:\n",
                "    print(f\"\\nüìä Distribuzione:\")\n",
                "    print(df['source'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.2 Verifica vocab.json\n",
                "import json\n",
                "\n",
                "# CRITICO: XLS-R DEVE usare lo stesso vocab di WavLM!\n",
                "vocab_path = Path('data/processed/vocab.json')\n",
                "if vocab_path.exists():\n",
                "    with open(vocab_path, encoding='utf-8') as f:\n",
                "        vocab = json.load(f)\n",
                "    print(f\"üìä Vocab: {len(vocab)} simboli\")\n",
                "    print(f\"   Esempio: {list(vocab.keys())[:10]}\")\n",
                "    print(f\"\\n‚úÖ Stesso vocab.json di WavLM - output allineati per ensemble\")\n",
                "else:\n",
                "    raise FileNotFoundError(\"‚ùå vocab.json non trovato!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configurazione Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.1 Configurazione (ottimizzata per XLS-R)\n",
                "import yaml\n",
                "import os\n",
                "\n",
                "# === CONFIGURAZIONE PRINCIPALE ===\n",
                "DRIVE_OUTPUT_DIR = '/content/drive/MyDrive/phoneme_xlsr'\n",
                "\n",
                "# XLS-R √® pi√π grande - batch size ridotto\n",
                "config = {\n",
                "    'seed': 42,\n",
                "    'model': {\n",
                "        'name': 'facebook/wav2vec2-xls-r-300m',\n",
                "        'freeze_feature_encoder': True\n",
                "    },\n",
                "    'data': {\n",
                "        'csv_path': DATASET_CSV,\n",
                "        'vocab_path': 'data/processed/vocab.json',\n",
                "        'audio_base_path': '.',\n",
                "        'val_size': 0.05,\n",
                "        'test_size': 0.05,\n",
                "        'sampling_rate': 16000\n",
                "    },\n",
                "    'training': {\n",
                "        'output_dir': DRIVE_OUTPUT_DIR,\n",
                "        'num_train_epochs': 10,\n",
                "        # Batch size ridotto per XLS-R (300M parametri)\n",
                "        'per_device_train_batch_size': 4,\n",
                "        'per_device_eval_batch_size': 4,\n",
                "        'gradient_accumulation_steps': 4,  # Effettivo: 4*4=16\n",
                "        'dataloader_num_workers': 0,\n",
                "        'dataloader_pin_memory': False,\n",
                "        'learning_rate': 3e-5,\n",
                "        'warmup_steps': 500,\n",
                "        'weight_decay': 0.01,\n",
                "        'optim': 'adamw_torch',\n",
                "        'max_grad_norm': 1.0,\n",
                "        'fp16': True,\n",
                "        'bf16': False,\n",
                "        'eval_strategy': 'epoch',\n",
                "        'save_strategy': 'epoch',\n",
                "        'save_total_limit': 2,  # Meno checkpoint (modello grande)\n",
                "        'load_best_model_at_end': True,\n",
                "        'metric_for_best_model': 'per',\n",
                "        'greater_is_better': False,\n",
                "        'logging_steps': 100,\n",
                "        'disable_tqdm': False,\n",
                "        'group_by_length': True,\n",
                "        # Gradient checkpointing per risparmiare VRAM\n",
                "        'gradient_checkpointing': True,\n",
                "    }\n",
                "}\n",
                "\n",
                "os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "# Salva config\n",
                "with open('configs/training_config_xlsr.yaml', 'w') as f:\n",
                "    yaml.dump(config, f, default_flow_style=False)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üìã CONFIGURAZIONE XLS-R (300M)\")\n",
                "print(\"=\"*60)\n",
                "print(f\"üìÅ Output: {DRIVE_OUTPUT_DIR}\")\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"üî¢ Epochs: {config['training']['num_train_epochs']}\")\n",
                "print(f\"üì¶ Batch: {config['training']['per_device_train_batch_size']} x {config['training']['gradient_accumulation_steps']} = {config['training']['per_device_train_batch_size'] * config['training']['gradient_accumulation_steps']}\")\n",
                "print(f\"üìà LR: {config['training']['learning_rate']}\")\n",
                "print(f\"üíæ Gradient Checkpointing: {config['training']['gradient_checkpointing']}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.2 Verifica checkpoint esistenti\n",
                "from pathlib import Path\n",
                "\n",
                "output_dir = Path(DRIVE_OUTPUT_DIR)\n",
                "checkpoints = []\n",
                "\n",
                "if output_dir.exists():\n",
                "    checkpoints = sorted([\n",
                "        d for d in output_dir.iterdir() \n",
                "        if d.is_dir() and d.name.startswith(\"checkpoint-\")\n",
                "    ])\n",
                "\n",
                "print(f\"üìÅ Output: {output_dir}\")\n",
                "if checkpoints:\n",
                "    print(f\"‚úÖ {len(checkpoints)} checkpoint trovati\")\n",
                "    for cp in checkpoints[-3:]:\n",
                "        print(f\"   üìÅ {cp.name}\")\n",
                "else:\n",
                "    print(\"‚ùå Nessun checkpoint - Training partir√† da zero\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.1 Avvia Training XLS-R\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
                "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
                "\n",
                "# === OPZIONI ===\n",
                "RESUME = \"auto\"\n",
                "\n",
                "drive_path = Path(DRIVE_OUTPUT_DIR)\n",
                "existing_checkpoints = []\n",
                "if drive_path.exists():\n",
                "    existing_checkpoints = sorted([\n",
                "        d for d in drive_path.iterdir() \n",
                "        if d.is_dir() and d.name.startswith(\"checkpoint-\")\n",
                "    ])\n",
                "\n",
                "if RESUME == \"auto\":\n",
                "    do_resume = len(existing_checkpoints) > 0\n",
                "else:\n",
                "    do_resume = bool(RESUME)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üöÄ AVVIO TRAINING XLS-R (wav2vec2-xls-r-300m)\")\n",
                "print(\"=\"*60)\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"üìÅ Output: {DRIVE_OUTPUT_DIR}\")\n",
                "print(f\"üîÑ Resume: {do_resume}\")\n",
                "print(\"\\n‚ö†Ô∏è XLS-R √® un modello grande - training pi√π lento (~2x WavLM)\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Comando\n",
                "cmd = f\"python scripts/train_xlsr.py --config configs/training_config_xlsr.yaml --data-csv {DATASET_CSV}\"\n",
                "if do_resume:\n",
                "    cmd += \" --resume\"\n",
                "\n",
                "!{cmd}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Valutazione"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5.1 Valutazione su SpeechOcean762\n",
                "MODEL_PATH = f\"{DRIVE_OUTPUT_DIR}/final_model_xlsr\"\n",
                "\n",
                "if Path(MODEL_PATH).exists():\n",
                "    print(f\"üî¨ Valutazione modello XLS-R: {MODEL_PATH}\")\n",
                "    !python scripts/05_evaluate_speechocean.py --model-path {MODEL_PATH}\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è Modello non trovato: {MODEL_PATH}\")\n",
                "    print(\"   Esegui prima il training!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Late Fusion (Ensemble)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.1 Verifica che entrambi i modelli esistano\n",
                "from pathlib import Path\n",
                "\n",
                "WAVLM_PATH = '/content/drive/MyDrive/phoneme_wavlm_weighted/final_model_weighted'\n",
                "XLSR_PATH = f\"{DRIVE_OUTPUT_DIR}/final_model_xlsr\"\n",
                "\n",
                "wavlm_exists = Path(WAVLM_PATH).exists()\n",
                "xlsr_exists = Path(XLSR_PATH).exists()\n",
                "\n",
                "print(\"üìä Stato modelli per Ensemble:\")\n",
                "print(f\"   WavLM Weighted: {'‚úÖ' if wavlm_exists else '‚ùå'} {WAVLM_PATH}\")\n",
                "print(f\"   XLS-R:          {'‚úÖ' if xlsr_exists else '‚ùå'} {XLSR_PATH}\")\n",
                "\n",
                "if wavlm_exists and xlsr_exists:\n",
                "    print(\"\\nüéâ Entrambi i modelli pronti per Late Fusion!\")\n",
                "else:\n",
                "    print(\"\\n‚ö†Ô∏è Addestra entrambi i modelli prima del fusion!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.2 Esegui Late Fusion\n",
                "from pathlib import Path\n",
                "\n",
                "WAVLM_PATH = '/content/drive/MyDrive/phoneme_wavlm_weighted/final_model_weighted'\n",
                "XLSR_PATH = f\"{DRIVE_OUTPUT_DIR}/final_model_xlsr\"\n",
                "\n",
                "# Peso per WavLM (0.5 = media semplice, 0.6 = favorisce WavLM)\n",
                "FUSION_WEIGHT = 0.5\n",
                "\n",
                "if Path(WAVLM_PATH).exists() and Path(XLSR_PATH).exists():\n",
                "    print(\"üî¨ Late Fusion Evaluation\")\n",
                "    print(f\"   Peso WavLM: {FUSION_WEIGHT}\")\n",
                "    print(f\"   Peso XLS-R: {1-FUSION_WEIGHT}\")\n",
                "    !python scripts/evaluate_fusion.py \\\n",
                "        --model-a {WAVLM_PATH} \\\n",
                "        --model-b {XLSR_PATH} \\\n",
                "        --weight {FUSION_WEIGHT}\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Uno o entrambi i modelli mancano\")\n",
                "    print(\"   Esegui prima i training separati!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.3 Ottimizza peso fusion\n",
                "from pathlib import Path\n",
                "\n",
                "WAVLM_PATH = '/content/drive/MyDrive/phoneme_wavlm_weighted/final_model_weighted'\n",
                "XLSR_PATH = f\"{DRIVE_OUTPUT_DIR}/final_model_xlsr\"\n",
                "\n",
                "if Path(WAVLM_PATH).exists() and Path(XLSR_PATH).exists():\n",
                "    print(\"üîç Ricerca peso ottimale...\\n\")\n",
                "    \n",
                "    for w in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
                "        print(f\"{'='*60}\")\n",
                "        print(f\"Peso WavLM: {w}, XLS-R: {1-w}\")\n",
                "        print(f\"{'='*60}\")\n",
                "        !python scripts/evaluate_fusion.py \\\n",
                "            --model-a {WAVLM_PATH} \\\n",
                "            --model-b {XLSR_PATH} \\\n",
                "            --weight {w} \\\n",
                "            --quiet\n",
                "        print()\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Modelli mancanti\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Salvataggio Finale"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7.1 Copia modello finale su Drive\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "\n",
                "LOCAL_MODEL = f\"{DRIVE_OUTPUT_DIR}/final_model_xlsr\"\n",
                "DRIVE_FINAL = '/content/drive/MyDrive/phoneme_models/xlsr'\n",
                "\n",
                "if Path(LOCAL_MODEL).exists():\n",
                "    Path(DRIVE_FINAL).parent.mkdir(parents=True, exist_ok=True)\n",
                "    shutil.copytree(LOCAL_MODEL, DRIVE_FINAL, dirs_exist_ok=True)\n",
                "    print(f\"‚úÖ Modello XLS-R copiato su: {DRIVE_FINAL}\")\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è Modello non trovato: {LOCAL_MODEL}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}