{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üåç XLS-R Training (Modello Multilingua)\n",
                "\n",
                "Questo notebook addestra **XLS-R** (wav2vec2-xls-r-300m), un modello multilingua pre-addestrato su 128 lingue.\n",
                "\n",
                "**Perch√© XLS-R?**\n",
                "- Pre-training su 128 lingue ‚Üí variet√† fonetica maggiore\n",
                "- Complementa WavLM (focalizzato su inglese)\n",
                "- Ottimo per speaker non-nativi\n",
                "\n",
                "**‚ö†Ô∏è IMPORTANTE:**\n",
                "- XLS-R √® un modello grande (300M parametri)\n",
                "- Richiede ~12GB VRAM (usa T4 o migliore)\n",
                "- Training pi√π lento di WavLM (~2x)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Ambiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.1 Verifica GPU\n",
                "!nvidia-smi\n",
                "\n",
                "import torch\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA disponibile: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    gpu_name = torch.cuda.get_device_name(0)\n",
                "    vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
                "    print(f\"GPU: {gpu_name}\")\n",
                "    print(f\"VRAM: {vram:.1f} GB\")\n",
                "    \n",
                "    if vram < 12:\n",
                "        print(\"\\n‚ö†Ô∏è ATTENZIONE: XLS-R richiede ~12GB VRAM\")\n",
                "        print(\"   Potrebbe essere necessario ridurre batch_size\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.2 Monta Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "print(\"‚úÖ Drive montato\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.3 Estrai progetto da zip\n",
                "import os\n",
                "import zipfile\n",
                "from pathlib import Path\n",
                "\n",
                "ZIP_PATH = '/content/drive/MyDrive/phonemeRef.zip'\n",
                "EXTRACT_PATH = '/content/DeepLearning-Phoneme'\n",
                "\n",
                "if not os.path.exists(ZIP_PATH):\n",
                "    raise FileNotFoundError(f\"‚ùå File non trovato: {ZIP_PATH}\\nCarica phonemeRef.zip su Google Drive\")\n",
                "\n",
                "print(f\"üì¶ Estrazione {ZIP_PATH}...\")\n",
                "with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
                "    zip_ref.extractall('/content/')\n",
                "\n",
                "# Trova cartella estratta\n",
                "extracted = [f for f in os.listdir('/content/') if os.path.isdir(f'/content/{f}') and 'Phoneme' in f]\n",
                "if extracted:\n",
                "    EXTRACT_PATH = f'/content/{extracted[0]}'\n",
                "\n",
                "os.chdir(EXTRACT_PATH)\n",
                "print(f\"‚úÖ Progetto in: {EXTRACT_PATH}\")\n",
                "!ls -la"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.4 Installa dipendenze\n",
                "!pip install -q transformers datasets evaluate jiwer accelerate soundfile librosa pyyaml tqdm audiomentations\n",
                "!pip install -q torchcodec\n",
                "print(\"\\n‚úÖ Dipendenze installate\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preparazione Dataset\n",
                "\n",
                "**‚ö†Ô∏è IMPORTANTE:** Usa lo stesso dataset di WavLM per l'ensemble!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.1 Carica e analizza dataset\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "\n",
                "# Opzioni dataset (DEVE essere lo stesso di WavLM!)\n",
                "DATASET_OPTIONS = [\n",
                "    'data/processed/combined_augmented.csv',\n",
                "    'data/processed/combined_dataset.csv',\n",
                "    'data/processed/phonemeref_processed.csv',\n",
                "]\n",
                "\n",
                "DATASET_CSV = None\n",
                "for opt in DATASET_OPTIONS:\n",
                "    if Path(opt).exists():\n",
                "        DATASET_CSV = opt\n",
                "        break\n",
                "\n",
                "if not DATASET_CSV:\n",
                "    raise FileNotFoundError(\"‚ùå Nessun dataset trovato!\")\n",
                "\n",
                "df = pd.read_csv(DATASET_CSV)\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"   Samples: {len(df):,}\")\n",
                "print(f\"\\n‚ö†Ô∏è IMPORTANTE: Usa lo stesso dataset di WavLM per l'ensemble!\")\n",
                "print(f\"\\n=== Distribuzione ===\")\n",
                "if 'source' in df.columns:\n",
                "    print(df['source'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.2 Verifica qualit√† IPA (cerca placeholder invalidi E annotazioni)\n",
                "import pandas as pd\n",
                "import re\n",
                "\n",
                "df = pd.read_csv(DATASET_CSV)\n",
                "\n",
                "# 1. Cerca IPA invalidi (placeholder [word])\n",
                "placeholder_mask = df['ipa_clean'].str.contains(r'^\\[.*\\]$', regex=True, na=False)\n",
                "\n",
                "# 2. Cerca annotazioni problematiche (adj., n., v., etc.)\n",
                "annotation_mask = df['ipa_clean'].str.contains(\n",
                "    r'adj\\.|n\\.|v\\.|adv\\.|interj\\.|for \\d|unstressed|stressed|esp\\.|also|Brit\\.|;',\n",
                "    regex=True, na=False\n",
                ")\n",
                "\n",
                "# 3. IPA troppo corti (< 2 caratteri)\n",
                "short_mask = df['ipa_clean'].str.len() < 2\n",
                "\n",
                "invalid_mask = placeholder_mask | annotation_mask | short_mask\n",
                "invalid_count = invalid_mask.sum()\n",
                "\n",
                "print(f\"üîç Analisi qualit√† IPA:\")\n",
                "print(f\"   Totale samples: {len(df):,}\")\n",
                "print(f\"   IPA placeholder [word]: {placeholder_mask.sum():,}\")\n",
                "print(f\"   IPA con annotazioni (adj., v., etc.): {annotation_mask.sum():,}\")\n",
                "print(f\"   IPA troppo corti (<2): {short_mask.sum():,}\")\n",
                "print(f\"   Totale invalidi: {invalid_count:,} ({100*invalid_count/len(df):.1f}%)\")\n",
                "\n",
                "if invalid_count > 0:\n",
                "    print(f\"\\n‚ö†Ô∏è ATTENZIONE: {invalid_count} samples hanno IPA problematici!\")\n",
                "    \n",
                "    # Mostra esempi\n",
                "    print(\"\\n   Esempi di IPA invalidi:\")\n",
                "    examples = df[invalid_mask][['word', 'ipa_clean']].head(10)\n",
                "    for _, row in examples.iterrows():\n",
                "        print(f\"   - {row['word']}: '{row['ipa_clean']}'\")\n",
                "    \n",
                "    # Rimuovi invalidi\n",
                "    df_clean = df[~invalid_mask].copy()\n",
                "    DATASET_CLEAN = 'data/processed/phonemeref_clean.csv'\n",
                "    df_clean.to_csv(DATASET_CLEAN, index=False)\n",
                "    print(f\"\\n‚úÖ Dataset pulito salvato: {DATASET_CLEAN}\")\n",
                "    print(f\"   Samples validi: {len(df_clean):,}\")\n",
                "    DATASET_CSV = DATASET_CLEAN\n",
                "else:\n",
                "    print(\"\\n‚úÖ Tutti gli IPA sono validi!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.3 Fix path e rimuovi file mancanti\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "\n",
                "df = pd.read_csv(DATASET_CSV)\n",
                "\n",
                "def fix_path(path_str):\n",
                "    \"\"\"Converte path Windows in path Colab.\"\"\"\n",
                "    path_str = str(path_str).replace('\\\\', '/')\n",
                "    \n",
                "    # Se √® gi√† un path relativo corretto (data/...), usalo\n",
                "    if path_str.startswith('data/'):\n",
                "        return path_str\n",
                "    \n",
                "    # Se inizia con 'audio/' (path relativo senza prefisso)\n",
                "    if path_str.startswith('audio/'):\n",
                "        return 'data/raw/phonemeref_data/' + path_str\n",
                "    \n",
                "    # Se contiene 'audio/' ma non 'data/', aggiungi il prefisso corretto\n",
                "    if '/audio/' in path_str:\n",
                "        idx = path_str.find('/audio/')\n",
                "        return 'data/raw/phonemeref_data' + path_str[idx:]\n",
                "    \n",
                "    # Se contiene path Windows assoluto con 'data/'\n",
                "    if 'data/' in path_str:\n",
                "        idx = path_str.find('data/')\n",
                "        return path_str[idx:]\n",
                "    \n",
                "    return path_str\n",
                "\n",
                "# Fix path\n",
                "df['audio_path'] = df['audio_path'].apply(fix_path)\n",
                "\n",
                "# === RIMUOVI FILE MANCANTI ===\n",
                "print(\"üîç Verifica esistenza file audio...\")\n",
                "missing_files = []\n",
                "existing_mask = []\n",
                "\n",
                "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking files\"):\n",
                "    exists = Path(row['audio_path']).exists()\n",
                "    existing_mask.append(exists)\n",
                "    if not exists:\n",
                "        missing_files.append((row.get('word', '?'), row['audio_path']))\n",
                "\n",
                "existing_mask = pd.Series(existing_mask, index=df.index)\n",
                "n_missing = len(missing_files)\n",
                "n_total = len(df)\n",
                "\n",
                "print(f\"\\nüìä Risultato verifica:\")\n",
                "print(f\"   Totale samples: {n_total:,}\")\n",
                "print(f\"   File esistenti: {n_total - n_missing:,} ({100*(n_total-n_missing)/n_total:.1f}%)\")\n",
                "print(f\"   File mancanti: {n_missing:,} ({100*n_missing/n_total:.1f}%)\")\n",
                "\n",
                "if n_missing > 0:\n",
                "    print(f\"\\n‚ö†Ô∏è Esempi file mancanti:\")\n",
                "    for word, path in missing_files[:10]:\n",
                "        print(f\"   ‚ùå {word}: {path}\")\n",
                "    \n",
                "    # Rimuovi file mancanti\n",
                "    df_clean = df[existing_mask].copy()\n",
                "    print(f\"\\n‚úÖ Rimossi {n_missing} samples con file mancanti\")\n",
                "    print(f\"   Dataset finale: {len(df_clean):,} samples\")\n",
                "    df = df_clean\n",
                "else:\n",
                "    print(\"\\n‚úÖ Tutti i file audio esistono!\")\n",
                "\n",
                "# Verifica distribuzione finale\n",
                "if 'source' in df.columns:\n",
                "    print(f\"\\nüìä Distribuzione finale:\")\n",
                "    print(df['source'].value_counts())\n",
                "\n",
                "# Salva\n",
                "DATASET_FINAL = 'data/processed/phonemeref_ready.csv'\n",
                "df.to_csv(DATASET_FINAL, index=False)\n",
                "print(f\"\\n‚úÖ Dataset pronto: {DATASET_FINAL}\")\n",
                "DATASET_CSV = DATASET_FINAL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2.4 Verifica vocab.json\n",
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "# CRITICO: XLS-R DEVE usare lo stesso vocab di WavLM!\n",
                "vocab_path = Path('data/processed/vocab.json')\n",
                "if vocab_path.exists():\n",
                "    with open(vocab_path, encoding='utf-8') as f:\n",
                "        vocab = json.load(f)\n",
                "    print(f\"üìä Vocab: {len(vocab)} simboli\")\n",
                "    print(f\"   Esempio: {list(vocab.keys())[:10]}\")\n",
                "    print(f\"\\n‚úÖ Stesso vocab.json di WavLM - output allineati per ensemble\")\n",
                "else:\n",
                "    raise FileNotFoundError(\"‚ùå vocab.json non trovato!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configurazione Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.1 Configurazione (ottimizzata per XLS-R)\n",
                "import yaml\n",
                "import os\n",
                "\n",
                "# === CONFIGURAZIONE PRINCIPALE ===\n",
                "DRIVE_OUTPUT_DIR = '/content/drive/MyDrive/phoneme_xlsr'\n",
                "\n",
                "# XLS-R √® pi√π grande - batch size ridotto\n",
                "config = {\n",
                "    'seed': 42,\n",
                "    'model': {\n",
                "        'name': 'facebook/wav2vec2-xls-r-300m',\n",
                "        'freeze_feature_encoder': True\n",
                "    },\n",
                "    'data': {\n",
                "        'csv_path': DATASET_CSV,\n",
                "        'vocab_path': 'data/processed/vocab.json',\n",
                "        'audio_base_path': '.',\n",
                "        'val_size': 0.05,\n",
                "        'test_size': 0.05,\n",
                "        'sampling_rate': 16000\n",
                "    },\n",
                "    'training': {\n",
                "        'output_dir': DRIVE_OUTPUT_DIR,\n",
                "        'num_train_epochs': 10,\n",
                "        # Batch size ridotto per XLS-R (300M parametri)\n",
                "        'per_device_train_batch_size': 4,\n",
                "        'per_device_eval_batch_size': 4,\n",
                "        'gradient_accumulation_steps': 4,  # Effettivo: 4*4=16\n",
                "        'dataloader_num_workers': 0,\n",
                "        'dataloader_pin_memory': False,\n",
                "        'learning_rate': 3e-5,\n",
                "        'warmup_steps': 500,\n",
                "        'weight_decay': 0.01,\n",
                "        'optim': 'adamw_torch',\n",
                "        'max_grad_norm': 1.0,\n",
                "        'fp16': True,\n",
                "        'bf16': False,\n",
                "        'eval_strategy': 'epoch',\n",
                "        'save_strategy': 'epoch',\n",
                "        'save_total_limit': 2,  # Meno checkpoint (modello grande)\n",
                "        'load_best_model_at_end': True,\n",
                "        'metric_for_best_model': 'per',\n",
                "        'greater_is_better': False,\n",
                "        'logging_steps': 100,\n",
                "        'disable_tqdm': False,\n",
                "        'group_by_length': True,\n",
                "        # Gradient checkpointing per risparmiare VRAM\n",
                "        'gradient_checkpointing': True,\n",
                "    }\n",
                "}\n",
                "\n",
                "os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "# Salva config\n",
                "with open('configs/training_config_xlsr.yaml', 'w') as f:\n",
                "    yaml.dump(config, f, default_flow_style=False)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üìã CONFIGURAZIONE XLS-R (300M)\")\n",
                "print(\"=\"*60)\n",
                "print(f\"üìÅ Output: {DRIVE_OUTPUT_DIR}\")\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"üî¢ Epochs: {config['training']['num_train_epochs']}\")\n",
                "print(f\"üì¶ Batch: {config['training']['per_device_train_batch_size']} x {config['training']['gradient_accumulation_steps']} = {config['training']['per_device_train_batch_size'] * config['training']['gradient_accumulation_steps']}\")\n",
                "print(f\"üìà LR: {config['training']['learning_rate']}\")\n",
                "print(f\"üíæ Gradient Checkpointing: {config['training']['gradient_checkpointing']}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.2 Verifica checkpoint esistenti\n",
                "from pathlib import Path\n",
                "import json\n",
                "\n",
                "output_dir = Path(DRIVE_OUTPUT_DIR)\n",
                "checkpoints = []\n",
                "\n",
                "if output_dir.exists():\n",
                "    checkpoints = sorted([\n",
                "        d for d in output_dir.iterdir() \n",
                "        if d.is_dir() and d.name.startswith(\"checkpoint-\")\n",
                "    ])\n",
                "\n",
                "print(f\"üìÅ Output: {output_dir}\")\n",
                "print(\"-\"*50)\n",
                "\n",
                "if checkpoints:\n",
                "    print(f\"‚úÖ {len(checkpoints)} checkpoint trovati:\")\n",
                "    \n",
                "    last_epoch = 0\n",
                "    best_per = None\n",
                "    \n",
                "    for cp in checkpoints[-3:]:\n",
                "        state_file = cp / \"trainer_state.json\"\n",
                "        if state_file.exists():\n",
                "            with open(state_file) as f:\n",
                "                state = json.load(f)\n",
                "            epoch = state.get('epoch', 0)\n",
                "            step = state.get('global_step', 0)\n",
                "            best = state.get('best_metric', None)\n",
                "            \n",
                "            last_epoch = max(last_epoch, epoch)\n",
                "            if best:\n",
                "                best_per = best\n",
                "            \n",
                "            info = f\"Epoch {epoch:.1f}, Step {step}\"\n",
                "            if best:\n",
                "                info += f\", Best PER: {best:.4f}\"\n",
                "            print(f\"   üìÅ {cp.name}: {info}\")\n",
                "    \n",
                "    target_epochs = config['training']['num_train_epochs']\n",
                "    if last_epoch >= target_epochs:\n",
                "        print(f\"\\n‚ö†Ô∏è TRAINING GI√Ä COMPLETATO! (epoch {last_epoch} >= {target_epochs})\")\n",
                "    else:\n",
                "        print(f\"\\n‚úÖ Training pu√≤ continuare per {target_epochs - last_epoch:.0f} epoche\")\n",
                "else:\n",
                "    print(\"‚ùå Nessun checkpoint - Training partir√† da zero\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.1 Avvia Training XLS-R\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
                "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
                "\n",
                "# === OPZIONI ===\n",
                "RESUME = \"auto\"\n",
                "\n",
                "drive_path = Path(DRIVE_OUTPUT_DIR)\n",
                "existing_checkpoints = []\n",
                "if drive_path.exists():\n",
                "    existing_checkpoints = sorted([\n",
                "        d for d in drive_path.iterdir() \n",
                "        if d.is_dir() and d.name.startswith(\"checkpoint-\")\n",
                "    ])\n",
                "\n",
                "if RESUME == \"auto\":\n",
                "    do_resume = len(existing_checkpoints) > 0\n",
                "else:\n",
                "    do_resume = bool(RESUME)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üöÄ AVVIO TRAINING XLS-R (wav2vec2-xls-r-300m)\")\n",
                "print(\"=\"*60)\n",
                "print(f\"üìä Dataset: {DATASET_CSV}\")\n",
                "print(f\"üìÅ Output: {DRIVE_OUTPUT_DIR}\")\n",
                "print(f\"üîÑ Resume: {do_resume}\")\n",
                "print(\"\\n‚ö†Ô∏è XLS-R √® un modello grande - training pi√π lento (~2x WavLM)\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Comando\n",
                "cmd = f\"python scripts/train_xlsr.py --config configs/training_config_xlsr.yaml --data-csv {DATASET_CSV}\"\n",
                "if do_resume:\n",
                "    cmd += \" --resume\"\n",
                "\n",
                "!{cmd}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Valutazione"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5.1 Visualizza curve di training\n",
                "import json\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "\n",
                "# Trova trainer_state.json\n",
                "state_path = None\n",
                "for loc in [\n",
                "    Path(DRIVE_OUTPUT_DIR) / 'final_model_xlsr' / 'trainer_state.json',\n",
                "    Path(DRIVE_OUTPUT_DIR) / 'trainer_state.json',\n",
                "]:\n",
                "    if loc.exists():\n",
                "        state_path = loc\n",
                "        break\n",
                "\n",
                "# Cerca anche nell'ultimo checkpoint\n",
                "if not state_path:\n",
                "    checkpoints = sorted([\n",
                "        d for d in Path(DRIVE_OUTPUT_DIR).iterdir() \n",
                "        if d.is_dir() and d.name.startswith(\"checkpoint-\")\n",
                "    ]) if Path(DRIVE_OUTPUT_DIR).exists() else []\n",
                "    if checkpoints:\n",
                "        state_path = checkpoints[-1] / 'trainer_state.json'\n",
                "\n",
                "if state_path and state_path.exists():\n",
                "    with open(state_path) as f:\n",
                "        state = json.load(f)\n",
                "    \n",
                "    log_history = state.get('log_history', [])\n",
                "    \n",
                "    # Estrai metriche\n",
                "    train_loss = [(h['step'], h['loss']) for h in log_history if 'loss' in h and 'eval_loss' not in h]\n",
                "    eval_loss = [(h['step'], h['eval_loss']) for h in log_history if 'eval_loss' in h]\n",
                "    eval_per = [(h['step'], h['eval_per']) for h in log_history if 'eval_per' in h]\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "    \n",
                "    if train_loss:\n",
                "        steps, losses = zip(*train_loss)\n",
                "        axes[0].plot(steps, losses, 'b-', alpha=0.7)\n",
                "        axes[0].set_xlabel('Step')\n",
                "        axes[0].set_ylabel('Loss')\n",
                "        axes[0].set_title('Training Loss')\n",
                "        axes[0].grid(True, alpha=0.3)\n",
                "    \n",
                "    if eval_loss:\n",
                "        steps, losses = zip(*eval_loss)\n",
                "        axes[1].plot(steps, losses, 'r-o')\n",
                "        axes[1].set_xlabel('Step')\n",
                "        axes[1].set_ylabel('Eval Loss')\n",
                "        axes[1].set_title('Validation Loss')\n",
                "        axes[1].grid(True, alpha=0.3)\n",
                "    \n",
                "    if eval_per:\n",
                "        steps, pers = zip(*eval_per)\n",
                "        axes[2].plot(steps, [p*100 for p in pers], 'g-o')\n",
                "        axes[2].set_xlabel('Step')\n",
                "        axes[2].set_ylabel('PER (%)')\n",
                "        axes[2].set_title('Phoneme Error Rate')\n",
                "        axes[2].grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f'{DRIVE_OUTPUT_DIR}/training_curves.png', dpi=150)\n",
                "    plt.show()\n",
                "    \n",
                "    if eval_per:\n",
                "        best_per = min(pers)\n",
                "        print(f\"\\nüèÜ Migliore PER: {best_per*100:.2f}%\")\n",
                "else:\n",
                "    print(\"‚ùå trainer_state.json non trovato - training non ancora completato?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5.2 Valutazione su SpeechOcean762\n",
                "MODEL_PATH = f\"{DRIVE_OUTPUT_DIR}/final_model_xlsr\"\n",
                "\n",
                "if Path(MODEL_PATH).exists():\n",
                "    print(f\"üî¨ Valutazione modello XLS-R: {MODEL_PATH}\")\n",
                "    !python scripts/05_evaluate_speechocean.py --model-path {MODEL_PATH}\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è Modello non trovato: {MODEL_PATH}\")\n",
                "    print(\"   Esegui prima il training!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Late Fusion (Ensemble)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.1 Verifica che entrambi i modelli esistano\n",
                "from pathlib import Path\n",
                "\n",
                "WAVLM_PATH = '/content/drive/MyDrive/phoneme_wavlm_weighted/final_model_weighted'\n",
                "XLSR_PATH = f\"{DRIVE_OUTPUT_DIR}/final_model_xlsr\"\n",
                "\n",
                "wavlm_exists = Path(WAVLM_PATH).exists()\n",
                "xlsr_exists = Path(XLSR_PATH).exists()\n",
                "\n",
                "print(\"üìä Stato modelli per Ensemble:\")\n",
                "print(f\"   WavLM Weighted: {'‚úÖ' if wavlm_exists else '‚ùå'} {WAVLM_PATH}\")\n",
                "print(f\"   XLS-R:          {'‚úÖ' if xlsr_exists else '‚ùå'} {XLSR_PATH}\")\n",
                "\n",
                "if wavlm_exists and xlsr_exists:\n",
                "    print(\"\\nüéâ Entrambi i modelli pronti per Late Fusion!\")\n",
                "else:\n",
                "    print(\"\\n‚ö†Ô∏è Addestra entrambi i modelli prima del fusion!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.2 Esegui Late Fusion\n",
                "from pathlib import Path\n",
                "\n",
                "WAVLM_PATH = '/content/drive/MyDrive/phoneme_wavlm_weighted/final_model_weighted'\n",
                "XLSR_PATH = f\"{DRIVE_OUTPUT_DIR}/final_model_xlsr\"\n",
                "\n",
                "# Peso per WavLM (0.5 = media semplice, 0.6 = favorisce WavLM)\n",
                "FUSION_WEIGHT = 0.5\n",
                "\n",
                "if Path(WAVLM_PATH).exists() and Path(XLSR_PATH).exists():\n",
                "    print(\"üî¨ Late Fusion Evaluation\")\n",
                "    print(f\"   Peso WavLM: {FUSION_WEIGHT}\")\n",
                "    print(f\"   Peso XLS-R: {1-FUSION_WEIGHT}\")\n",
                "    !python scripts/evaluate_fusion.py \\\n",
                "        --model-a {WAVLM_PATH} \\\n",
                "        --model-b {XLSR_PATH} \\\n",
                "        --weight {FUSION_WEIGHT}\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Uno o entrambi i modelli mancano\")\n",
                "    print(\"   Esegui prima i training separati!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Salvataggio Finale"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7.1 Verifica contenuto su Drive\n",
                "from pathlib import Path\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"üìÅ CONTENUTO SU GOOGLE DRIVE\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Cartella: {DRIVE_OUTPUT_DIR}\")\n",
                "print(\"-\"*60)\n",
                "\n",
                "drive_path = Path(DRIVE_OUTPUT_DIR)\n",
                "if drive_path.exists():\n",
                "    for item in sorted(drive_path.iterdir()):\n",
                "        if item.is_dir():\n",
                "            n_files = len(list(item.rglob(\"*\")))\n",
                "            print(f\"  üìÅ {item.name}/ ({n_files} files)\")\n",
                "        else:\n",
                "            size_mb = item.stat().st_size / 1e6\n",
                "            print(f\"  üìÑ {item.name} ({size_mb:.1f} MB)\")\n",
                "\n",
                "    final_model = drive_path / \"final_model_xlsr\"\n",
                "    if final_model.exists():\n",
                "        print(\"\\n‚úÖ Modello finale presente!\")\n",
                "    else:\n",
                "        print(\"\\n‚ö†Ô∏è Modello finale non trovato\")\n",
                "else:\n",
                "    print(\"‚ùå Cartella non trovata\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7.2 Crea zip per download\n",
                "import os\n",
                "\n",
                "FINAL_MODEL = f'{DRIVE_OUTPUT_DIR}/final_model_xlsr'\n",
                "ZIP_PATH = f'{DRIVE_OUTPUT_DIR}/final_model_xlsr.zip'\n",
                "\n",
                "if os.path.exists(FINAL_MODEL):\n",
                "    !cd {FINAL_MODEL} && zip -r {ZIP_PATH} .\n",
                "    print(f\"\\n‚úÖ Zip creato: {ZIP_PATH}\")\n",
                "    !ls -lh {ZIP_PATH}\n",
                "else:\n",
                "    print(\"‚ùå Modello finale non trovato\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üéâ Fine\n",
                "\n",
                "Il modello √® salvato su Google Drive:\n",
                "- `final_model_xlsr/` - Modello trainato\n",
                "- `final_model_xlsr.zip` - Per download rapido\n",
                "- `training_curves.png` - Grafici\n",
                "- `checkpoint-*/` - Checkpoint intermedi"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}